
## 概述
1. 数据结构是什么？
	研究数据的存储方式

2. 数据结构有哪些？
	大致包含以下几种：
	1. 线性表
		- 可细分为顺序表、链表、栈和队列。
		- 线性表并不是一种具体的存储结构，它包含顺序存储结构和链式存储结构，是顺序表和链表的统称。
	2. 树结构，包括普通树，二叉树，线索二叉树等；
	3. 图存储结构；

3. 时间复杂度和空间复杂度
	算法，即解决问题的方法。同一个问题，使用不同的算法，虽然得到的结果相同，但是耗费的时间和资源是不同的。
	运行效率体现在两方面：
	- 算法的运行时间。（称为“时间复杂度”）
	- 运行算法所需的内存空间大小。（称为“空间复杂度”）
	- `O(1)常数阶` < `O(logn)对数阶` < `O(n)线性阶` < `O(n2)平方阶` < `O(n3)(立方阶)` < `O(2n) (指数阶)`



## 线性表
线性表用于存储具有“一对一”逻辑关系的数据；
1. 顺序表
2. 链表
3. 静态链表
4. 双向链表

## 栈和队列
### 栈
1. 概念
	- 栈也是用来存储逻辑关系为 "一对一" 数据的线性存储结构
	- 栈只能从表的一端存取数据，另一端是封闭的.
	- 在栈中，无论是存数据还是取数据，都必须遵循"先进后出"的原则，即最先进栈的元素最后出栈
	- 栈的开口端被称为栈顶,封口端被称为栈底。
2. 进栈和出栈
	- 向栈中添加元素，此过程被称为"进栈"（入栈或压栈）；
	- 从栈中提取出指定元素，此过程被称为"出栈"（或弹栈）；
3. 栈的具体实现
	- 顺序栈：采用顺序存储结构可以模拟栈存储数据的特点，从而实现栈存储结构；
	- 链栈：采用链式存储结构实现栈结构；

### 队列
1. 概念
	- 队列，和栈一样，也是一种对数据的"存"和"取"有严格要求的线性存储结构。
	- 队列的两端都"开口"，要求数据只能从一端进，从另一端出。
	- 进数据的一端为 "队尾"，出数据的一端为 "队头"，数据元素进队列的过程称为 "入队"，出队列的过程称为 "出队"。
	- 队列中数据的进出要遵循 "先进先出" 的原则
	- 栈和队列不要混淆，栈结构是一端封口，特点是"先进后出"；而队列的两端全是开口，特点是"先进先出"。
2. 队列的实现
	- 顺序队列：在顺序表的基础上实现的队列结构；
	- 链队列：在链表的基础上实现的队列结构；


## 字符串
1. 概念
	- 数据结构中，字符串要单独用一种存储结构来存储，称为串存储结构。
	- 串存储结构也是一种线性存储结构，因为字符串中的字符之间也具有"一对一"的逻辑关系。
2. 串结构的实现
	- 定长顺序存储：实际上就是用普通数组（又称静态数组）存储。
	- 堆分配存储：用动态数组存储字符串；
	- 块链存储：用链表存储字符串；
3. 匹配模式
	1. BF算法
	2. KMP算法(难点)

## 数组和广义表
### 数组
#### 概念
- 从本质上讲，数组与顺序表、链表、栈和队列一样，都用来存储具有 "一对一" 逻辑关系数据的线性存储结构。
- 无论数组的维数是多少，数组中的数据类型都必须一致。
- 一维数组结构是线性表的基本表现形式，而 n 维数组可理解为是对线性存储结构的一种扩展。
	
####  数组的顺序存储
- 数组作为一种线性存储结构，对存储的数据通常只做查找和修改操作，因此数组结构的实现使用的是顺序存储结构。
- C 语言中，多维数组的存储采用的是以行序为主的顺序存储方式。
- 两种先后存储方式
	- 以列序为主（先列后行）：按照行号从小到大的顺序，依次存储每一列的元素
	- 以行序为主（先行后序）：按照列号从小到大的顺序，依次存储每一行的元素。

####  矩阵（稀疏矩阵）压缩存储
- 数据结构中，提供针对某些特殊矩阵的压缩存储结构。
	- 含有大量相同数据元素的矩阵，比如对称矩阵；
	- 含有大量 0 元素的矩阵，比如稀疏矩阵、上（下）三角矩阵；

针对以上两类矩阵，数据结构的压缩存储思想是：矩阵中的相同数据元素（包括元素 0）只存储一个。

1. **对称矩阵**
	
	数据元素沿主对角线对应相等，这类矩阵称为对称矩阵。
	
	矩阵中有两条对角线，其中图 1 中的对角线称为主对角线，另一条从左下角到右上角的对角线为副对角线。**对称矩阵指的是各数据元素沿主对角线对称的矩阵**。结合数据结构压缩存储的思想，我们可以使用一维数组存储对称矩阵。
	
	设行标i, 列标j，则
	下三角公式：`k = i*(i-1)/2+j-1`
	上三角公式：`k = j*(j-1)/2+i-1`
	k 值即为该元素存储到数组中的位置（矩阵中元素的行标和列标都从 1 开始）。
	
	以上两个公式既是用来存储矩阵中元素的，也用来从数组中提取矩阵相应位置的元素。



2. **上（下）三角矩阵**

	- 主对角线下的数据元素全部相同(例如都是0)的矩阵为上三角矩阵
	- 主对角线上的数据元素全部相同(例如都是0)的矩阵为下三角矩阵
	- 对于这类特殊的矩阵，压缩存储的方式是： 上（下）三角矩阵采用对称矩阵的方式存储上（下）三角的数据（元素 0 不用存储）
	- 上(下)三角矩阵存储元素和提取元素的过程和对称矩阵相同。



3. **稀疏矩阵**
	- 如果矩阵中分布有大量的元素 0，即非 0 元素非常少，这类矩阵称为稀疏矩阵。
	- 压缩存储稀疏矩阵的方法是：只存储矩阵中的非 0 元素，与前面的存储方法不同，稀疏矩阵非 0 元素的存储需同时存储该元素所在矩阵中的行标和列标。

    例如：
    (1,1,1)：数据元素为 1，在矩阵中的位置为 (1,1)；
    (3,3,1)：数据元素为 3，在矩阵中的位置为 (3,1)；
    (5,2,3)：数据元素为 5，在矩阵中的位置为 (2,3)；
    除此之外，还要存储矩阵的行数 3 和列数 3；
   
> note: 以上 3 种特殊矩阵的压缩存储，除了将数据元素存储起来，还要存储矩阵的行数值和列数值



- 矩阵压缩存储的 3 种方式

  - 对阵矩阵和上下三角矩阵的实现方法是相同的，且实现过程比较容易，仅需套用上面给出的公式即可
  - 稀疏矩阵的压缩存储，数据结构提供有 3 种具体实现方式：
      1. **三元组顺序表**
      2. **行逻辑链接的顺序表**
      3. **十字链表**

#### 矩阵运算
以下几种全部基于线性代数中的算法，但是代码我没太搞明白，尤其是乘法和加法

- 矩阵（稀疏矩阵）的转置算法
- 稀疏矩阵的快速转置
- 矩阵乘法（基于行逻辑链接的顺序表）
- 矩阵加法（基于十字链表）




### 广义表




#### 广义表的存储结构




#### 广义表的深度和长度

广义表的长度，指的是广义表中所包含的数据元素的个数（空表{} 的长度为0）。

广义表的深度，可以通过观察该表中所包含括号的层数间接得到。


#### 广义表的复制







## 树
树结构用于存储具有“一对多”关系的数据；
1. 普通树
2. 二叉树
3. 线索二叉树

### 树的概念

#### *结点*

- 结    点： 每一个数据元素都被称为“结点”。
- 父结点：元素的上一级结点(一个)。
- 子结点：元素的下一级结点(多个)。
- 兄弟结点：同一个父结点的子结点互为兄弟节点(相互)。
- 根结点：非空树结构顶点(没有父节点了)
- 叶结点：如果结点没有任何子结点，那么此结点称为叶子结点（叶结点）。

####  *子树和空树*

- 子树： 树是由根结点和若干棵子树构成的。
	- 以某个结点为根结点，直到遍历完以下的所有结点，这些合集称为子树
	- 单个结点也是一棵树，根结点是它本身。
- 空树： 如果集合本身为空，那么构成的树就被称为空树。(空树中没有结点)
- 在树结构中，对于具有同一个根结点的各个子树，相互之间不能有交集。

####  *结点的度和层次*

- 结点的度: 对于一个结点，拥有的子树数（结点有多少分支）称为结点的度（Degree）。
- 结点的层次：从一棵树的树根开始，树根所在层为第一层，根的孩子结点所在的层为第二层，依次类推。	

> 一棵树的度, 是树内各结点的度的最大值。
> 一棵树的深度, 是树中结点所在的最大的层次。
> 如果两个结点的父结点虽不相同，但处在同一层上，那么这两个结点互为堂兄弟。


#### *有序树和无序树*

如果树中结点的子树从左到右，谁在左边，谁在右边，是有规定的，顺序排列的称为有序树；反之称为无序树。

在有序树中，一个结点最左边的子树称为"第一个孩子"，最右边的称为"最后一个孩子"。


#### *森林*

由 m（m >= 0）个互不相交的树组成的集合被称为森林。
树还可以理解为是由根结点和森林组成的。

根结点外，每一颗子树都看成独立的，则组成森林。

Tree =（root,F）

root: 根结点
F: forest 由 m（m >= 0）棵子树组成的森林



### 二叉树

成为二叉树的条件：
- 本身是有序树；
- 树中包含的各个节点的度不能超过 2，即只能是 0、1 或者 2；

#### 性质

1. 二叉树中，第n层最多有 2<sup>i-1</sup>  个结点。
2. 如果二叉树的深度为 K，那么此二叉树最多有 2<sup>K</sup>-1 个结点。
3. 二叉树中，终端结点数（叶子结点数）为 n<sub>0</sub>，度为 2 的结点数为 n<sub>2</sub>，则 n<sub>0</sub>=n<sub>2</sub>+1。


#### 满二叉树

如果二叉树中除了叶子结点，每个结点的度都为 2，则此二叉树称为满二叉树。

满二叉树除了具有二叉树的全部性质外，还具有以下性质：

1. 满二叉树中第 n 层的节点数为 2<sup>n-1</sup> 个。
2. 深度为 k 的满二叉树必有 2<sup>k</sup>-1 个节点 ，叶子数为 2<sup>k-1</sup>。
3. 满二叉树中不存在度为 1 的节点，每一个分支点中都两棵深度相同的子树，且叶子节点都在最底层。
4. 具有 n 个节点的满二叉树的深度为 log<sub>2</sub>(n+1)。



#### 完全二叉树

如果二叉树中除去最后一层节点为满二叉树，且最后一层的结点依次从左到右分布，则此二叉树被称为完全二叉树。

完全二叉树除了具有二叉树的全部性质外，还具有以下性质：

1. n 个结点的完全二叉树的深度为 ⌊log<sub>2</sub>n⌋ +1 (表示取小于 log<sub>2</sub>n 的最大整数)。
2. 当 i>1 时，父亲结点为结点  ⌊i/2⌋。（i=1 时，表示的是根结点，无父亲结点）
3. 如果 `2*i>n`（总结点的个数） ，则结点 i 肯定没有左孩子（为叶子结点）；否则其左孩子是结点 `2*i` 。
4. 如果 `2*i+1>n` ，则结点 i 肯定没有右孩子；否则右孩子是结点 `2*i+1` 。

### 二叉树的存储结构

#### 顺序存储结构

- 顾名思义，就是用顺序表（数组）存储二叉树。
- 顺序表只适用于完全二叉树。
- 如果要用顺序结构存储普通二叉树，需要先转换为完全二叉树
- 满二叉树也是完全二叉树，因为它满足完全二叉树的所有特征

转换为完全二叉树的方法就是给二叉树添加结点，使其满足完全二叉树的条件(例如添加若干个0)。

**完全二叉树的顺序存储，仅需从根节点开始，按照层次依次将树中节点存储到数组即可(层级遍历)。**


#### 链式存储结构

普通的二叉树，若将其采用链式存储，则只需从树的根节点开始，将各个节点及其左右孩子使用链表存储即可。

采用链式存储二叉树时，其节点结构由 3 部分构成：

- 指向左孩子节点的指针（Lchild）；
- 节点存储的数据（data）；
- 指向右孩子节点的指针（Rchild）；

另外，如果要找到父节点的话，可以添加一个指针，指向父节点，称为三叉结点。


### 二叉树的遍历算法

#### 层次遍历

通过对树中各层的节点从左到右依次遍历，即可实现对正棵二叉树的遍历，此种方式称为层次遍历。

成功遍历二叉树的标志是能够成功访问到二叉树中所有的节点

队列实现层次遍历：

- 根结点1入队；
- 根结点1出队，并将左2右3孩子分别入队；
- 队头结点 2 出队，并将结点 2 的左孩子 4 和右孩子 5 依次入队；
- 队头结点 3 出队，并将结点 3 的左孩子 6 和右孩子 7 依次入队；
- 不断地循环，直至队列内为空。
- 次序：1 2 4 5 3 6 7


#### 先序遍历

每遇到一个节点，先访问，然后再遍历其左右子树

二叉树先序遍历的实现思想是：

- 访问根节点；
- 访问当前节点的左子树；
- 若当前节点无左子树，则访问当前节点的右子树；
- 次序：1 2 4 5 3 6 7

#### 中序遍历

第一次经过时不访问，等遍历完左子树之后再访问，然后遍历右子树
次序：4 2 5 1 6 3 7

#### 后序遍历

第一次和第二次经过时都不访问，等遍历完该节点的左右子树之后，最后访问该节点
次序：4 5 2 6 7 3 1



### 线索二叉树

在遍历的同时，使用二叉树中空闲的内存空间记录**某些**结点的前趋和后继元素的位置。这
样在算法后期需要遍历二叉树时，就可以利用保存的结点信息，提高了遍历的效率。使用这种方法构建的二叉树，即为“线索二叉树”。

#### 线索二叉树的结点结构

如果在二叉树中想保存每个结点前趋和后继所在的位置信息，最直接的想法就是改变结点的结构，即添加两个指针域，分别指向该结点的前趋和后继。

但是这种方式会降低树存储结构的存储密度。而对于二叉树来讲，其本身还有很多未利用的空间。

> 存储密度指的是数据本身所占的存储空间和整个结点结构所占的存储量之比。

每一棵二叉树上，很多结点都含有未使用的指向NULL 的指针域。除了度为2 的结点，度为1 的结点，有一个空的指针域；叶子结点两个指针域都为NULL。

> 规律：在有n 个结点的二叉链表中必定存在n+1 个空指针域。

线索二叉树实际上就是使用这些空指针域来存储结点之间前趋和后继关系的一种特殊的二叉树。

- 如果结点有左子树，则lchild 指针域指向左孩子，否则指向该结点的**直接前驱**。
- 如果结点有右子树，则rchild 指针域指向右孩子，否则指向该结点的**直接后继**。
- 为了避免指针域指向的结点的意义混淆，需要额外增加两个标志域LTag，RTag。
	- LTag 值为0 时，表示lchild 指针域指向的是该结点的左孩子；为1 时，表示指向的是该结点的直接前驱；
	- RTag 值为0 时，表示rchild 指针域指向的是该结点的右孩子；为1 时，表示指向的是该结点的直接后继。

| lchild       | LTag     | data | RTag     | rchild       |
| ------------ | -------- | ---- | -------- | ------------ |
| 左子节点指针 | 左标志域 | 数据 | 右标志域 | 右子节点指针 |

- 使用上表所示的结点结构组成的二叉链表，被称为**线索链表**
- 构建的二叉树称为**线索二叉树**。
- 线索链表中的“线索”，指的是链表中指向结点前趋和后继的指针。
- 二叉树经过某种遍历方法转化为线索二叉树的过程称为线索化。

#### 对二叉树进行线索化

将二叉树转化为线索二叉树，实质上是在遍历二叉树的过程中，将二叉链表中的空指针改为指向直接前趋或者直接后继的线索(线索化的过程即为在遍历的过程中修改空指针的过程)。

在遍历过程中，如果当前结点没有左孩子，需要将该结点的lchild 指针指向遍历过程中的前一个结点，所以在遍历过程中，设置一个指针（名为pre ），时刻指向当前访问结点的前一个结点。

#### 使用线索二叉树遍历

```
a->lchild = b;  
a->rchild = c; 
c->lchild = d;  
c->rchild = e;
e->lchild = f;  
e->rchild = g;
```
使用线索二叉树时（假设使用中序），会经常遇到一个问题，结点d 的直接后继直接通过指针域获得，为结点c ；而由于结点c 的度为2 ，无法利用指针域指向后继结点，整个链表断掉了。当在遍历过程，遇到这种问题是解决的办法就是：*寻找先序、中序、后序遍历的规律，找到下一个结点*。

先序遍历:
如果结点因为有右孩子导致无法找到其后继结点，如果结点有左孩子，则后继结点是其左孩子；否则，就一定是右孩子。
如上表，结点a 的后继结点是其左孩子结点b ，如果结点b 不存在的话，就是结点c 。

中序遍历:
结点的后继是遍历其右子树时访问的第一个结点，也就是右子树中位于最左下的结点。
如上表, 结点c ，后继结点为结点f ，是其右子树中位于最左边的结点。反之，结点的前趋是左子树最后访问的那个结点。

后序遍历中找后继结点需要分为3 种情况（复杂）：
1. 如果该结点是二叉树的根，后继结点为空；
2. 如果该结点是父结点的右孩子，但是父结点没有左孩子（或者是左孩子，但是父结点没有右孩子），后继结点是父结点；
3. 如果该结点是父结点的左孩子，且父结点有右子树，后继结点为父结点的右子树在后序遍历列出的第一个结点。


使用后序遍历建立的线索二叉树，在真正使用过程中遇到链表的断点时，需要访问父结点，所以在初步建立二叉树时，宜采用三叉链表做存储结构。

### 双向线索二叉树

双向线索链表的作用就是可以让线索二叉树从两个方向实现遍历。

#### 实现过程

在线索二叉树的基础上，额外添加一个结点。此结点的作用类似于链表中的头指针，数据域不起作用，只利用两个指针域（由于都是指针，标志域都为0 ）。

- 左指针域指向二叉树的树根，确保可以正方向对二叉树进行遍历
- 右指针域指向线索二叉树形成的线性序列中的最后一个结点

这样，二叉树中的线索链表就变成了双向线索链表，既可以从第一个结点通过不断地找后继结点进行遍历，也可以从最后一个结点通过不断找前趋结点进行遍历。

#### 双向线索二叉树的遍历

双向线索二叉树遍历时，如果正向遍历，就从树的根结点开始。整个遍历过程结束的标志是：当从头结点出发，遍历回头结点时，表示遍历结束。

逆向遍历线索二叉树的过程即从头结点的右指针指向的结点出发，逐个寻找直接前趋结点，结束标志同正向遍历一样。



### 树的几种存储表示法

#### 树的双亲表示法

- 双亲表示法采用顺序表（数组）存储普通树
- 核心思想是：顺序存储各个节点的同时，给各节点附加一个记录其父节点位置的变量。
- 根节点没有父节点（父节点又称为双亲节点），因此根节点记录父节点位置的变量通常置为 -1。


#### 树的孩子表示法

- 孩子表示法存储普通树采用的是 "顺序表+链表" 的组合结构
- 存储过程是：从树的根节点开始，使用顺序表依次存储树中各个节点
- 孩子表示法会给各个节点配备一个链表，用于存储各节点的孩子节点位于顺序表中的位置。
- 如果节点没有孩子节点（叶子节点），则该节点的链表为空链表。


#### 树的孩子兄弟表示法

- 树结构中，位于同一层的节点之间互为兄弟节点。
- 孩子兄弟表示法，采用的是链式存储结构
- 存储树的实现思想是：从树的根节点开始，依次用链表存储各个节点的孩子节点和兄弟节点。
- 该链表中的节点应包含以下 3 部分内容
	1. 节点的值；
	2. 指向孩子节点的指针；
	3. 指向兄弟节点的指针； 

即通过孩子兄弟表示法，任意一棵普通树都可以相应转化为一棵二叉树，换句话说，任意一棵普通树都有唯一的一棵二叉树于其对应。

孩子兄弟表示法可以作为将普通树转化为二叉树的最有效方法，通常又被称为"二叉树表示法"或"二叉链表表示法"。


### 森林转换为二叉树

森林，指的是由n（n>=2）棵互不相交的树组成的集合。

任意一棵普通树都可以转化为二叉树，而森林是由多棵普通树构成的，因此自然也可以转化为二叉树。森林转化为二叉树，更多的是为了对森林中的节点做遍历操作。

1. 首先将森林中所有的普通树各自转化为二叉树；
2. 将森林中第一棵树的树根作为整个森林的树根，其他树的根节点看作是第一棵树根结点的兄弟结点，采用孩子兄弟表示法将所有树进行连接；

转化前的森林与转化后的二叉树相比，其层次遍历和后序遍历的访问节点顺序不同，而前序遍历和中序遍历访问节点的顺序是相同的。



### 霍夫曼树

霍夫曼树，也叫“哈夫曼树”、“赫夫曼树”、“最优树”或“最优二叉树”。

当用 n 个结点（都做叶子结点且都有各自的权值）试图构建一棵树时，如果构建的这棵树的带权路径长度(WPL)最小，称这棵树为“霍夫曼树”。

在构建霍夫曼树时，要使树的带权路径长度最小，只需要遵循一个原则，那就是：**权重越大的结点离树根越近**，所以权值最大的结点直接作为根结点的孩子结点。



#### 名词解释

**路径：**  在一棵树中，一个结点到另一个结点之间的通路，称为路径。

**路径长度：**  在一条路径中，每经过一个结点，路径长度都要加 1 ，到达目标结点所经过的结点数就是路径长度。 

**结点的权：**  给每一个结点赋予一个特定的数来代表它的值，这个值被称为这个结点的权值。 

**结点的带权路径长度：**  指的是从根结点到目标结点之间的路径长度与目标结点的权值的乘积。

**WPL：**  树的带权路径长度为树中所有叶子结点的带权路径长度之和。通常记作 “WPL” 。



#### 构建霍夫曼树

对于给定的有各自权值的 n 个结点，构建霍夫曼树有一个行之有效的办法：

1. 在 n 个权值中选出两个最小的权值，对应的两个结点组成一个新的二叉树，且新二叉树的根结点的权值为左右孩子权值的和；
2. 在原有的 n 个权值中删除那两个最小的权值，同时将新的权值加入到 n–2 个权值的行列中，以此类推；
3. 重复 1 和 2 ，直到所以的结点构建成了一棵二叉树为止，这棵树就是霍夫曼树。



#### 霍夫曼树中结点结构

由于哈夫曼树的构建是从叶子结点开始的，不断地构建新的父结点，直至构建完成，所以结点中应包含指向父结点的指针。但是在使用哈夫曼树时是从树根开始，根据需求遍历树中的结点，因此每个结点需要有指向其左孩子和右孩子的指针。

```c
//哈夫曼树结点结构
typedef struct {
    int weight;//结点权值
    int parent, left, right;//父结点、左孩子、右孩子在数组中的位置下标
}HTNode, *HuffmanTree;
```



#### 霍夫曼树的查找算法

构建哈夫曼树时，需要每次根据各个结点的权重值，筛选出其中值最小的两个结点，然后构建二叉树。

查找权重值最小的两个结点的思想是：从数组起始位置开始，首先找到两个无父结点的结点，然后和后续无父结点的结点依次做比较，有两种情况需要考虑：

- 如果比两个结点中较小的那个还小，就保留这个结点，删除原来较大的结点；
- 如果介于两个结点权重值之间，替换原来较大的结点；



#### 哈夫曼编码

哈夫曼编码就是在哈夫曼树的基础上构建的，这种编码方式最大的优点就是用最少的字符包含最多的信息内容。

根据发送信息的内容，通过统计文本中相同字符的个数作为每个字符的权值，建立哈夫曼树。对于树中的每一个子树，统一规定其左孩子标记为 0 ，右孩子标记为 1 。这样，用到哪个字符时，从哈夫曼树的根结点开始，依次写出经过结点的标记，最终得到的就是该结点的哈夫曼编码。

> 文本中字符出现的次数越多，在哈夫曼树中的体现就是越接近树根。编码的长度越短。

使用程序求哈夫曼编码有两种方法：

1. 从叶子结点一直找到根结点，逆向记录途中经过的标记。
2. 从根结点出发，一直到叶子结点，记录途中经过的标记。



### 回溯算法

回溯法，又被称为“试探法”。解决问题时，每进行一步，都是抱着试试看的态度，如果发现当前选择并不是最好的，或者这么走下去肯定达不到目标，立刻做回退操作重新选择。这种走不通就回退再走的方法就是回溯法。

例如，在解决列举集合 {1,2,3} 中所有子集的问题中，就可以使用回溯法。从集合的开头元素开始，对每个元素都有两种选择：取还是舍。当确定了一个元素的取舍之后，再进行下一个元素，直到集合最后一个元素。其中的每个操作都可以看作是一次尝试，每次尝试都可以得出一个结果。将得到的结果综合起来，就是集合的所有子集。


回溯和递归并不是一回事，虽然回溯用到了递归，但这也是他们之间唯一的联系：*回溯法可以用递归思想实现*。

回溯法从问题本身出发，寻找可能实现的所有情况。和穷举法的思想相近。

- 穷举法是将所有的情况都列举出来以后再一一筛选
- 回溯法在列举过程如果发现当前情况根本不可能存在，就停止后续的所有工作，返回上一步进行新的尝试。
- 递归是从问题的结果出发，例如求 n！，要想知道 n！的结果，就需要知道 n*(n-1)! 的结果，而要想知道 (n-1)! 结果，就需要提前知道 (n-1)*(n-2)!。这样不断地向自己提问，不断地调用自己的思想就是递归。

#### 回溯法与树的遍历

使用回溯法解决问题的过程，实际上是建立一棵“状态树”的过程。

回溯法的求解过程实质上是先序遍历“状态树”的过程。树中每一个叶子结点，都有可能是问题的答案。

在某些情况下，回溯法解决问题的过程中创建的状态树并不都是满二叉树，因为在试探的过程中，有时会发现此种情况下，再往下进行没有意义，所以会放弃这条死路，回溯到上一步。在树中的体现，就是在树的最后一层不是满的，即不是满二叉树，需要自己判断哪些叶子结点代表的是正确的结果。



### 多个结点的二叉树种类

本节要讨论的是当给定 n（n>=0）个结点时，可以构建多少种形态不同的树。

> 如果两棵树中各个结点的位置都一一对应，可以说这两棵树相似。如果两棵树不仅相似，而且对应结点上的数据也相同，就可以说这两棵树等价。本节中，形态不同的树指的是互不相似的树。

前面介绍过，对于任意一棵普通树，通过孩子兄弟表示法的转化，都可以找到唯一的一棵二叉树与之对应。所以本节研究的题目也可以转化成：**n 个结点可以构建多少种形态不同的二叉树**。

每一棵普通树对应的都是一棵没有右子树的二叉树，所以对于 n 个结点的树来说，树的形态改变是因为除了根结点之外的其它结点改变形态得到的，所以，**n 个结点构建的形态不同的树与之对应的是 n-1 个结点构建的形态不同的二叉树**。

如果 t<sub>n</sub>表示 n 个结点构建的形态不同的树的数量，b<sub>n</sub>表示 n 个结点构建的形态不同的二叉树的数量，则两者之间有这样的关系：t<sub>n</sub>=b<sub>n</sub>-1



#### 方法

最直接的一种方法就是推理。

当 n=0 时，只能构建一棵空树
- 0(root)


当 n=2 时，可以构建 2 棵形态不同的二叉树
- 1(root) - 2(left)
- 1(root) - 2(right)

当 n=3 时，可以构建 5 棵形态互不相同的二叉树

- 1(root) - 2(left) - 3(2-left)
- 1(root) - 2(left) - 3(2-right)
- 1(root) - 2(left) - 3(right)
- 1(root) - 2(right) - 3(2-left)
- 1(root) - 2(right) - 3(2-right)

...

对于具有 n（ n>1 ）个结点的二叉树来说，都可以看成是一个根结点、由 i 个结点组成的左子树和由 `n-i-1` 个结点组成的右子树。

> 当 n=1 时，也适用，只不过只有一个根结点，没有左右孩子（i=0）。

$b_n = \frac{1}{n+1} *C^n_ {2n}$





## 图

### 图存储结构

图通常用来表示和存储具有“多对多”关系的数据，是数据结构中非常重要的一种结构。



图存储结构中，习惯上用 Vi 表示图中的顶点，且所有顶点构成的集合通常用 V 表示，如 V={V1,V2,V3,V4}。

另外，图中的顶点之间的联系并不都是双向的，如V1 -> V2 ，就是V1单向到V2，而V2并不指向V1。

因此，图存储结构可细分两种表现类型，分别为 **无向图** 和 **有向图** 。

#### 图中的一些名词

- **顶点**
	图中存储的各个数据元素被称为**顶点**



- **弧头和弧尾**
	有向图中，无箭头一端的顶点通常被称为 **"初始点"** 或 **"弧尾"** ，箭头直线的顶点被称为 **"终端点"** 或 **"弧头"**。



- **度**
	对于有向图中的一个顶点 V 来说，箭头指向 V 的弧的数量为 V 的 **入度**（InDegree，记为 ID(V) ；箭头远离 V 的弧的数量为 V 的 **出度**（OutDegree，记为OD(V)） ；入度和出度之和称为 **顶点的度**。



- **(V1,V2) 和 <V1,V2> 的区别**
	无向图中描述两顶点 V1 和 V2 之间的关系可以用 (V1,V2) 来表示，而有向图中描述从 V1 到 V2 的"单向"关系用 <V1,V2> 来表示。

	由于图存储结构中顶点之间的关系是用线来表示的，因此 (V1,V2) 还可以用来表示无向图中连接 V1 和 V2 的线，又称为 **边**；同样，<V1,V2> 也可用来表示有向图中从 V1 到 V2 带方向的线，又称为 **弧**。



- **集合 VR 的含义**
	图中习惯用 VR 表示图中所有顶点之间关系的集合。例如，无向图的集合 VR={(v1,v2),(v1,v4),(v1,v3),(v3,v4)}，图 2 中有向图的集合 VR={<v1,v2>,<v1,v3>,<v3,v4>,<v4,v1>}。



- **路径和回路**
	无论是无向图还是有向图，从一个顶点到另一顶点途径的所有顶点组成的序列（包含这两个顶点），称为一条**路径**。如果路径中第一个顶点和最后一个顶点相同，则此路径称为 **回路**（或"环"）。

	如果路径中各顶点都不重复，此路径又被称为 **简单路径**；同样，若回路中的顶点互不重复，此回路被称为 **简单回路**（或简单环）。

	*在有向图中，每条路径或回路都是有方向的*。



- **权和网的含义**
	在某些实际场景中，图中的每条边（或弧）会赋予一个实数来表示一定的含义，这种与边（或弧）相匹配的实数被称为 **权**，而带权的图通常称为 **网**。



- **子图**
	指的是由图中一部分顶点和边构成的图，称为原图的子图。



#### 图存储结构的分类

根据不同的特征，图又可分为 **完全图**，**连通图**，**稀疏图** 和 **稠密图**。

- **完全图**：若图中各个顶点都与除自身外的其他顶点有关系，这样的无向图称为完全图。
- **有向完全图**：满足完全图条件的有向图则称为有向完全图。
- **完全图的边的计算**：具有 n 个顶点的完全图，图中边的数量为 `n(n-1)/2`；而对于具有 n 个顶点的有向完全图，图中弧的数量为 `n(n-1)`。
- **稀疏图和稠密图**：这两种图是相对存在的，即如果图中具有很少的边（或弧），此图就称为"稀疏图"；反之，则称此图为"稠密图"。
- **稀疏和稠密的判断条件**：e<nlogn，其中 e 表示图中边的数量，n 表示图中顶点的数量。如果公式成立，则为稀疏图；反之为稠密图。
- **连通图**： 无向图中，如果任意两个顶点之间都能够连通，则称此无向图为连通图。




### 连通图

**连通图**：无向图中，如果任意两个顶点之间都能够连通，则称此无向图为连通图。

**连通分量**：若无向图不是连通图，但图中存储某个子图符合连通图的性质，则称该子图为连通分量。

**最大连通图**：由图中部分顶点和边构成的图为该图的一个子图，或把图的所有结点用最少的边将其连接起来的子图，称为最大连通图(也称"极大连通子图")；所以极大连通子图不唯一。



> Note:
> 1. 连通分量的提出是以"整个无向图不是连通图"为前提的.
> 2. 最大连通图不是以结点个数作为判断依据的，两个独立连接的结点和20个独立连接的结点都可以称为图的最大连通图。
> 3. 如果无向图是连通图，则其无法分解出多个最大连通子图，因为图中所有的顶点之间都是连通的。



**强连通图** ： 有向图中，若任意两个顶点 Vi 和 Vj，满足从 Vi 到 Vj 以及从 Vj 到 Vi 都连通，也就是都含有至少一条通路，则称此有向图为 **强连通图** 。

**强连通分量** ：同时，若有向图本身不是强连通图，但其包含的最大连通子图具有强连通图的性质，则称该子图为 **强连通分量** 。


- 连通图是在无向图的基础上对图中顶点之间的连通做了更高的要求。
- 强连通图是在有向图的基础上对图中顶点的连通做了更高的要求。



### 生成树

**生成树**：对连通图进行遍历，过程中所经过的边和顶点的组合可看做是一棵普通树，通常称为 **生成树** 。

连通图中，由于任意两顶点之间可能含有多条通路，遍历连通图的方式有多种，往往一张连通图可能有多种不同的生成树与之对应。

连通图中的生成树必须满足以下 2 个条件：
1. 包含连通图中所有的顶点；
2. 任意两顶点之间有且仅有一条通路；

因此，连通图的生成树具有这样的特征，即生成树中 `边的数量 = 顶点数 - 1`。



**生成森林**：非连通图中，多个连通分量对应的多颗生成树共同构成 **生成森林** 。

生成树是对应连通图来说，而生成森林是对应非连通图来说的。

非连通图可分解为多个连通分量，而每个连通分量又各自对应多个生成树（至少是 1 棵），因此与整个非连通图相对应的，是由多棵生成树组成的生成森林。



### 图的存储结构

#### 图的顺序存储结构

使用图结构表示的数据元素之间虽然具有“多对多”的关系，但是同样可以采用顺序存储，也就是使用数组有效地存储图。

使用数组存储图时，需要使用两个数组：一个数组存放图中顶点本身的数据（一维数组），另外一个数组用于存储各顶点之间的关系（二维数组）。

存储图中各顶点本身数据，使用一维数组就足够了；存储顶点之间的关系时，要记录每个顶点和其它所有顶点之间的关系，所以需要使用二维数组。

不同类型的图，存储的方式略有不同，根据图有无权，可以将图划分为两大类：

- **图**：包括无向图和有向图。存储图中顶点之间的关系时，如果顶点之间存在边，在数组的相应位置用 1 表示，反之用 0 表示。
- **网**：是指带权的图，包括无向网和有向网。存储网中顶点之间的关系时，如果顶点之间存在边，在数组的相应位置存储其权值；反之用 0 表示。

```c
#define MAX_VERtEX_NUM 20                   //顶点的最大个数
#define VRType int                          //表示顶点之间的关系的变量类型
#define InfoType char                       //存储边额外的信息指针变量类型
#define VertexType int                      //图中顶点的数据类型

typedef enum{DG,DN,UDG,UDN}GraphKind;       //枚举图的 4 种类型：有向图,有向网,无向图,无向网

typedef struct {
    VRType adj;                             //图，用 1 或 0 表示是否相邻；网，直接为权值或0。
    InfoType * info;                        //边额外含有的信息指针
}ArcCell,AdjMatrix[MAX_VERtEX_NUM][MAX_VERtEX_NUM];

// 结构
typedef struct {
    VertexType vexs[MAX_VERtEX_NUM];        //存储图中顶点数据
    AdjMatrix arcs;                         //二维数组，记录顶点之间的关系
    int vexnum,arcnum;                      //记录图的顶点数和边数
    GraphKind kind;                         //记录图的种类
}MGraph;
```

例如： 

![graph](http://data.biancheng.net/uploads/allimg/170905/2-1FZ5154Q5263.png)

无向图：
```
01010 // V1: 和V2，V4有关系
10100 // V2: 和V1,V3有关系
01011 // V3: 和V2,V4,V5有关系
10100 // V4: 和V1,V3有关系
00100 // V5: 和V3有关系
```

在此二维数组中，每一行代表一个顶点，依次从 V1 到 V5 ，每一列也是如此。

对于无向图来说，二维数组构建的二阶矩阵，实际上是对称矩阵，在存储时就可以采用压缩存储的方式存储下三角或者上三角。

通过二阶矩阵，可以直观地判断出各个顶点的度，为该行（或该列）非 0 值的和。例如，第一行有两个 1，说明 V1 有两个边，所以度为 2。

有向图：
```
0110
0000
0001
1000
```

通过二阶矩阵，可以很轻松得知各顶点的出度和入度，出度为该行之和，入度为该列之和。

- 第一行有两个1，出度为2，分别指向V2，V3；
- 第一列有一个1，则入度为1，来自V4；
- V1的度为两者之和3。
- `arcs[0][1] = 1` ，证明从 V1 到 V2 有边。



#### 图的邻接表存储结构

通常，图更多的是采用链表存储，具体的存储方法有 3 种，分别是邻接表、邻接多重表和十字链表。

邻接表既适用于存储无向图，也适用于存储有向图。

**邻接点**： 在图中，如果两个点相互连通，即通过其中一个顶点，可直接找到另一个顶点，则称它们互为邻接点。邻接指的是图中顶点之间有边或者弧的存在。

**邻接表存储图的实现方式**：给图中的各个顶点独自建立一个链表，用结点存储该顶点，用链表中其他结点存储各自的邻接点。

为了便于管理这些链表，通常会将所有链表的头节点存储到数组中（也可以用链表存储）。也正因为各个链表的头节点存储的是各个顶点，因此各链表在存储邻接点数据时，仅需存储该邻接顶点位于数组中的位置下标即可。

- **邻接表计算顶点的出度和入度**

    使用邻接表计算无向图中顶点的入度和出度会非常简单，只需从数组中找到该顶点然后统计此链表中节点的数量即可。

    使用邻接表存储有向图时，通常各个顶点的链表中存储的都是以该顶点为弧尾的邻接点，因此通过统计各顶点链表中的节点数量，只能计算出该顶点的出度，而无法计算该顶点的入度。

    对于利用邻接表求某顶点的入度，有两种方式：

    1. 遍历整个邻接表中的节点，统计数据域与该顶点所在数组位置下标相同的节点数量，即为该顶点的入度；
    2. 建立一个逆邻接表，该表中的各顶点链表专门用于存储以此顶点为弧头的所有顶点在数组中的位置下标。

对于具有 n 个顶点和 e 条边的无向图，邻接表中需要存储 n 个头结点和 2e 个表结点。在图中边稀疏的时候，使用邻接表要比前一节介绍的邻接矩阵更加节省空间。



#### 图的十字链表存储结构

与邻接表不同，十字链表法仅适用于存储有向图和有向网。不仅如此，十字链表法还改善了邻接表计算图中顶点入度的问题。

十字链表存储有向图（网）的方式与邻接表有一些相同，都以图（网）中各顶点为首元节点建立多条链表，同时为了便于管理，还将所有链表的首元节点存储到同一数组（或链表）中。

**首元节点** 中有一个数据域和两个指针域
`data | firstIn | firstOut`

- firstIn 指针用于连接以当前顶点为弧头的其他顶点构成的链表(入度)；
- firstOut 指针用于连接以当前顶点为弧尾的其他顶点构成的链表(出度)；
- data 用于存储该顶点中的数据；

> 十字链表实质上就是为每个顶点建立两个链表，分别存储以该顶点为弧头的所有顶点和以该顶点为弧尾的所有顶点。

**其他节点** 的结构和首元结点是不同的，它有两个位置下标和三个指针：
`tailVex | headVex | hlink | tlink | info`

- tailVex 用于存储以首元节点为弧尾的顶点的位于数组中的位置下标；
- headVex 用于存储以首元节点为弧头的顶点的位于数组中的位置下标；
- hlink 指针：用于链接下一个存储以首元节点为弧头的顶点的节点；
- tlink 指针：用于链接下一个存储以首元节点为弧尾的顶点的节点；
- info 指针：用于存储与该顶点相关的信息，例如量顶点之间的权值；

![十字链表存储有向图示意图](http://data.biancheng.net/uploads/allimg/190107/2-1Z10H11122456.gif)

拿图中的顶点 V1 来说，通过构建好的十字链表得知，以该顶点为弧头的顶点只有存储在数组中第 3 位置的 V4（因此该顶点的入度为 1），而以该顶点为弧尾的顶点有两个，分别为存储数组第 1 位置的 V2 和第 2 位置的 V3（因此该顶点的出度为 2）。

对于图中各个链表中节点来说，由于表示的都是该顶点的出度或者入度，因此没有先后次序之分。



#### 图的邻接多重表存储结构

无向图的存储可以使用邻接表，但在实际使用时，如果想对图中某顶点进行实操（修改或删除），由于邻接表中存储该顶点的节点有两个，因此需要操作两个节点。

邻接多重表仅适用于存储无向图或无向网。

邻接多重表存储无向图的方式，可看作是邻接表和十字链表的结合。同邻接表和十字链表存储图的方法相同，都是独自为图中各顶点建立一张链表，存储各顶点的节点作为各链表的首元节点，同时为了便于管理将各个首元节点存储到一个数组中。

邻接多重表采用与邻接表相同的首元节点结构。但各链表中其他节点的结构与十字链表中相同。

首元结点结构： 

- data：存储此顶点的数据；
- firstedge：指针域，用于指向同该顶点有直接关联的存储其他顶点的节点。

其他结点结构：

- mark：标志域，用于标记此节点是否被操作过，例如在对图中顶点做遍历操作时，为了防止多次操作同一节点，mark 域为 0 表示还未被遍历；mark 为 1 表示该节点已被遍历；
- ivex 和 jvex：数据域，分别存储图中各边两端的顶点所在数组中的位置下标；
- ilink：指针域，指向下一个存储与 ivex 有直接关联顶点的节点；
- jlink：指针域，指向下一个存储与 jvex 有直接关联顶点的节点；
- info：指针域，用于存储与该顶点有关的其他信息，比如无向网中各边的权；

![无向图及其对应的邻接多重表](http://data.biancheng.net/uploads/allimg/190108/2-1Z10R04Hb26.gif)

从图中，可直接找到与各顶点有直接关联的其他顶点。比如说，与顶点 V1 有关联的顶点为存储在数组下标 1 处的 V2 和数组下标 3 处的 V4，而与顶点 V2 有关联的顶点有 3 个，分别是 V1、V3 和 V5。



### 深度优先搜索和广度优先搜索

![无向图](http://data.biancheng.net/uploads/allimg/170905/2-1FZ51I14M57.png)

#### 深搜(DFS)

深度优先搜索(Depth First Search)的过程类似于树的先序遍历。

它的思想：假设初始状态是图中所有顶点均未被访问，则从某个顶点v出发，首先访问该顶点，然后依次从它的各个未被访问的邻接点出发深度优先搜索遍历图，直至图中所有和v有路径相通的顶点都被访问到。 若此时尚有其他顶点未被访问到，则另选一个未被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。

显然，深度优先搜索是一个递归的过程。

1. 访问V1
2. 访问V2(或V3),因为顺序存储时，V2排序在V3前面，所以先访问V2
3. 访问V4，同理
4. 访问V8
5. 访问V5
6. 由于左子树的所有邻接点都被访问过了。此时，从 V5 回退到 V8 ，看 V8 是否有未被访问过的邻接点，如果没有，继续回退到 V4 ， V2 ， V1 ，发现了V1有未被访问的邻接点V3.
7. 访问V3-V6-V7

而有向图的深搜就直接按照弧的方向，并根据无向图的规则进行访问即可。



#### 广搜(BFS)

广度优先搜索算法(Breadth First Search)，又称为"宽度优先搜索"或"横向优先搜索"，简称BFS。

广度优先搜索类似于树的层次遍历。从图中的某一顶点出发，遍历每一个顶点时，依次遍历其所有的邻接点，然后再从这些邻接点出发，同样依次访问它们的邻接点。按照此过程，直到图中所有被访问过的顶点的邻接点都被访问到。最后还需要做的操作就是查看图中是否存在尚未被访问的顶点，若有，则以该顶点为起始点，重复上述遍历的过程。

还拿上图图中的无向图为例：

1. 访问起始点V1 ，访问其所有的邻接点 V2 和 V3。
2. 分别以 V2 和 V3 为起始点，访问邻接点 V4、V5 和  V6 、 V7。 
3. 以 V4 为起始点访问 V8 ，以 V5 为起始点，由于 V5 所有的起始点已经全部被访问，所有直接略过， V6 和 V7 也是如此。
4. 所以上面这个例子可以按照层级进行排序：V1 - V2 - V3 - V4 - V5 - V6 - V7 - V8





### 深度优先生成树和广度优先生成树

其实在对无向图进行遍历的时候，遍历过程中所经历过的图中的顶点和边的组合，就是图的生成树或者生成森林。

![无向图](http://data.biancheng.net/uploads/allimg/170912/2-1F912163410958.png)

由 **深度优先搜索** 得到的树为 **深度优先生成树**。
由 **广度优先搜索** 生成的树为 **广度优先生成树**。

图中的无向图是由 V1～V7 的顶点和编号分别为 a～i 的边组成。

当使用 *深度优先搜索算法* 时，假设 V1 作为遍历的起始点，涉及到的顶点和边的遍历顺序为（不唯一）：

![img](http://data.biancheng.net/uploads/allimg/170912/2-1F912163444395.png)

深度优先生成树：

![深度优先生成树](http://data.biancheng.net/uploads/allimg/170912/2-1F912163502E8.png)

广度优先生成树：

![广度优先生成树](http://data.biancheng.net/uploads/allimg/170912/2-1F912163551311.png)



#### 非连通图的生成森林

非连通图在进行遍历时，实则是对非连通图中每个连通分量分别进行遍历，在遍历过程经过的每个顶点和边，就构成了每个连通分量的生成树。

非连通图中，多个连通分量构成的多个生成树为非连通图的生成森林。



#### 深度优先生成森林

![深度优先生成森林](http://data.biancheng.net/uploads/allimg/170912/2-1F912163A4559.png)

对上图中的非连通图 （a） 采用 *深度优先搜索算法* 遍历时，得到的 *深度优先生成森林*（由 3 个深度优先生成树构成）如 （b） 所示（不唯一）。

非连通图在遍历生成森林时，可以采用 *孩子兄弟表示法* 将森林转化为一整棵二叉树进行存储。

![孩子兄弟表示法表示深度优先生成森林](http://data.biancheng.net/uploads/allimg/170912/2-1F912163P2F9.png)



#### 广度优先生成森林

非连通图采用广度优先搜索算法进行遍历时，经过的顶点以及边的集合为该图的广度优先生成森林。

拿上图（a）中的非连通图为例，通过广度优先搜索得到的广度优先生成森林用孩子兄弟表示法为： 

![广度优先生成森林](http://data.biancheng.net/uploads/allimg/170912/2-1F912163U9C6.png)


### 求最小生成树

简单得理解就是

给定一个带有权值的连通图（连通网），如何从众多的生成树中筛选出权值总和最小的生成树，即为该图的 **最小生成树**。

给定一个连通网，求最小生成树的方法有：**普里姆（Prim）算法** 和 **克鲁斯卡尔（Kruskal）算法** 。



#### Prim 算法

普里姆算法在找最小生成树时，将顶点分为两类，一类是在查找的过程中已经包含在树中的（设为A 类），剩下的是另一类（设为B 类）。

1. 对于给定的连通网，起始状态全部顶点都归为B 类
2. 在找最小生成树时，选定任意一个顶点作为起始点，并将之从B 类移至A类
3. 找出B 类中到A 类中的顶点之间最小权值的顶点，将之从B 类移至A 类
4. 如此重复，直到B 类中没有顶点为止。

所走过的顶点和边就是该连通图的最小生成树。

普里姆算法的运行效率只与连通网中包含的顶点数相关，而和网所含的边数无关。所以普里姆算法适合于解决边稠密的网，该算法运行的时间复杂度为：O(n<pre>2</pre>)。

如果连通网中所含边的绸密度不高，则建议使用克鲁斯卡尔算法



#### Kruskal 算法

Prim算法从顶点的角度出发，适合求稠密的网，时间复杂度为O(n<sup>2</sup>).

而Kruskal算法是从边的角度求网的最小生成树，适合于求边稀疏的网的最小生成树，时间复杂度为O(eloge).

对于任意一个连通网的最小生成树来说，在要求总的权值最小的情况下，最直接的想法就是将连通网中的所有边按照权值大小进行升序排序，从小到大依次选择。

由于最小生成树本身是一棵生成树，所以需要时刻满足以下两点：

- 生成树中任意顶点之间有且仅有一条通路，也就是说，生成树中不能存在回路
- 对于具有n 个顶点的连通网，其生成树中只能有n-1 条边，这n-1 条边连通着n 个顶点。

> 连接n 个顶点在不产生回路的情况下，只需要n-1 条边。

所以克鲁斯卡尔算法的具体思路是：

将所有边按照权值的大小进行升序排序，然后从小到大一一判断，条件为：如果这个边不会与之前选择的所有边组成回路，就可以作为最小生成树的一部分；反之，舍去，直到具有n 个顶点的连通网筛选出来n-1 条边为止。筛选出来的边和所有的顶点构成此连通网的最小生成树。

*判断是否会产生回路的方法为：在初始状态下给每个顶点赋予不同的标记，对于遍历过程的每条边，其都有两个顶点，判断这两个顶点的标记是否一致，如果一致，说明它们本身就处在一棵树中，如果继续连接就会产生回路；如果不一致，说明它们之间还没有任何关系，可以连接。*

假设遍历到一条由顶点A 和B 构成的边，而顶点A 和顶点B 标记不同，此时不仅需要将顶点A 的标记更新为顶点B 的标记，还需要更改所有和顶点A 标记相同的顶点的标记，全部改为顶点B 的标记。





### 重连通图及重连通分量

在无向图中，如果任意两个顶点之间含有不止一条通路，这个图就被称为 **重连通图 **。在重连通图中，在删除某个顶点及该顶点相关的边后，图中各顶点之间的连通性也不会被破坏。

在一个无向图中，如果删除某个顶点及其相关联的边后，原来的图被分割为两个及以上的连通分量，则称该顶点为无向图中的一个 **关节点** 或者 **割点**。

![连通图](http://data.biancheng.net/uploads/allimg/170911/2-1F9111F216335.png)

上图是连通图但不是重连通图，图中有4个关节点，分别是：A、B、D 和 G。比如删除顶点 B 及相关联的边后，原图就变为：

![连通分量](http://data.biancheng.net/uploads/allimg/170911/2-1F9111F253129.png)

可以看到，图被分割为各自独立的 3 部分，顶点集合分别为：

- {A、C、F、L、M、J}
- {G、H、I、K} 
- {D、E}

**重连通图其实就是没有关节点的连通图**

在重连通图中，只删除一个顶点及其相关联的边，肯定不会破坏其连通性。

*如果一味地做删除顶点的操作，直到删除 K 个顶点及其关联的边后，图的连通性才遭到破坏，则称此重连通图的连通度为 K*。



#### 判断重连通图的方法

对于任意一个连通图来说，都可以通过 **深度优先搜索算法** 获得一棵 **深度优先生成树**

图 1 通过深度优先搜索获得的深度优先生成树为

![深度优先生成树](http://data.biancheng.net/uploads/allimg/170911/2-1F9111F601611.png)

虚线表示遍历生成树时未用到的边，简称 **回边** 。也就是图中有，但是遍历时没有用到，生成树中用虚线表示出来。

在深度优先生成树中，图中的关节点有两种特性：

1. 首先判断整棵树的树根结点，如果树根有两条或者两条以上的子树，则该顶点肯定是关节点。因为一旦树根丢失，生成树就会变成森林。
2. 然后判断生成树中的每个非叶子结点，以该结点为根结点的每棵子树中如果有结点的回边与此非叶子结点的祖宗结点相关联，那么此非叶子结点就不是关节点；反之，就是关节点。

> 注意：必须是和该非叶子结点的祖宗结点（不包括结点本身）相关联，才说明此结点不是关节点。

*所以，判断一个图是否是重连通图，也可以转变为：判断图中是否有关节点，如果没有关节点，证明此图为重连通图；反之则不是。*

拿上图的生成树来说，利用两个特性判断每个顶点是否为关节点：

- 首先，判断树根结点 A ，由于有两个孩子，也就是有两棵子树，所以 A 是关节点。然后判断树中所有的非叶子结点，也就是： L 、 M 、 B 、 D 、 H 、 K 、 G ；
- L 结点为根结点的子树中 B 结点有回边直接关联 A ，所以， L 不是关节点；
- M 结点为树根的子树中，J 结点和 B 结点都有回边关联 M 结点的祖宗结点，所以，M 不是关节点；
- B 结点为根结点的 3 棵子树中，只有一棵子树（只包含叶子结点 C ）与 B 结点的祖宗结点 A 有关联，其他两棵子树没有，所以结点 B 是关节点；
- D 结点为根结点的子树中只有结点 E，且没有回边与祖宗结点关联，所以，D 是关节点；
- H 结点为根结点的子树中， G 结点与 B 结点关联，所以， H 结点不是关节点；
- K 结点和 H 结点相同，由于 G 结点与祖宗结点 B 关联，所以 K 结点不是关节点；
- G 结点为根结点的子树中只有一个结点 I，没有回边，所以结点 G 是关节点；

综上所述，上图中的关节点有 4 个，分别是： A 、 B 、 D 、 G 。





### 拓扑排序算法

对一个有向无环图G进行拓扑排序，是将G中所有顶点排成一个线性序列，使得图中任意一对顶点 u 和 v ，若边 <u,v>∈E(G)，则 u 在线性序列中出现在 v 之前。通常，这样的线性序列称为满足拓扑次序(Topological Order)的序列，简称 **拓扑序列** 。

简单的说，拓扑排序指的是将有向无环图中的顶点按照图中指定的先后顺序进行排序，或者说由某个集合上的一个 **偏序** 得到该集合上的一个 **全序**，这个操作称之为 **拓扑排序**。

**有向无环图** 指的是一个无回路的有向图，也叫无回路有向图， 简称DAG （Directed Acyclic Graph）。

图不好画，脑补一下吧

- 偏序关系： {V1 --> V2 --> V4  ,V1 --> V3 --> V4} 
- 全序关系： {V1 --> V2 --> V3 --> V4, V1 --> V3, V2 --> V4} 
- 他们都是有向无环图 

在有向无环图中，弧的方向代表着顶点之间的先后次序，例如从V1 指向V2 的弧表示在进行排序时V1 在前， V2 在后。

**全序是偏序的一种特殊情况**。 对于任意一个有向无环图来说，通过拓扑排序得到的序列首先一定是偏序，如果任意两个顶点都具有前后顺序，那么此序列是全序。



#### 拓扑排序的方法

对有向无环图进行拓扑排序，只需要遵循两个原则：
1. 在图中选择一个没有前驱的顶点V；
2. 从图中删除顶点V 和所有以该顶点为尾的弧。

有向无环图如果顶点本身具有某种实际意义，例如用有向无环图表示大学期间所学习的全部课程，每个顶点都表示一门课程，有向边表示课程学习的先后次序，例如要先学《程序设计基础》和《离散数学》，然后才能学习《数据结构》。

**所以用来表示某种活动间的优先关系的有向图简称为 *AOV网* **。

- 如果顶点之间只是具有偏序关系，那么拓扑排序的结果肯定不唯一
- 如果顶点之间是全序关系，那么拓扑排序得到的序列唯一

#### 拓扑排序的实现

在编写程序解决拓扑排序的问题时，大致思路为：

首先通过邻接表将AOV 网进行存储，由于拓扑排序的整个过程中，都是以顶点的入度为依据进行排序，所以需要根据建立的邻接表统计出各顶点的入度。

在得到各顶点的入度后，首先找到入度为0 的顶点作为拓扑排序的起始点，然后查找以该顶点为起始点的所有顶点，如果入度为1，说明如果删除前一个顶点后，该顶点的入度为0，为拓扑排序的下一个对象。





### 关键路径

求关键路径针对的是 AOE 网。

#### AOE 网

**AOE 网** 是在 AOV 网的基础上，其中每一个边都具有各自的权值，是一个有向无环网。其中权值表示活动持续的时间。

![AOE网](http://data.biancheng.net/uploads/allimg/170912/2-1F912154422b1.png)

如图所示就是一个 AOE 网，例如 a1=6 表示完成 a1 活动完成需要 6 天；AOE 网中每个顶点表示在它之前的活动已经完成，可以开始后边的活动，例如 V5 表示 a4 和 a5 活动已经完成，a7 和 a8 可以开始。

使用 AOE 网可以帮助解决这样的问题：*如果将 AOE 网看做整个项目，那么完成整个项目至少需要多少时间？*

解决这个问题的关键在于从 AOE 网中找到一条从起始点到结束点长度最长的路径，这样就能保证所有的活动在结束之前都能完成。

- 起始点是入度为 0 的点，称为 **源点**
- 结束点是出度为 0 的点，称为 **汇点**
- 这条最长的路径，称为 **关键路径**

#### 关键路径

为了求出一个给定 AOE 网的关键路径，需要知道以下 4 个统计数据：

- 对于 AOE 网中的顶点有两个时间：最早发生时间（用 Ve(j) 表示）和最晚发生时间（用 Vl(j) 表示）；
- 对于边来说，也有两个时间：最早开始时间（用 e(i) 表示）和最晚开始时间（ l(i) 表示）。

**最早发生时间 Ve(j)**

对于 AOE 网中的任意一个顶点来说，从源点到该点的最长路径代表着该顶点的最早发生时间，通常用 Ve(j) 表示。

>  例如，从 V1 到 V5 有两条路径，V1 作为源点开始后，a1 和 a2 同时开始活动，但由于 a1 和 a2 活动的时间长度不同，最终 V1-V3-V5 的这条路径率先完成。但是并不是说 V5 之后的活动就可以开始，而是需要等待 V1-V2-V5 这条路径也完成之后才能开始。所以对于 V5 来讲，Ve(5) = 7。

**最晚发生时间 Vl(j)**

表示在不推迟整个工期的前提下，事件 Vk 允许的最晚发生时间。

>  例如，在得知整个工期完成的时间是 18 天的前提下，V7 最晚要在第 16 天的时候开始，因为 a10 活动至少需要 2 天时间才能完成，如果在 V7 事件在推迟，就会拖延整个工期。所以，对于 V7 来说，它的 Vl(7)=16。

**最早开始时间 e(i)**

表示活动 ai 的最早开始时间，如果活动 ai 是由弧 <Vk,Vj> 表示的，那么活动 ai 的最早开始的时间就等于时间 Vk 的最早发生时间，也就是说：e[i] = ve[k]。

> 例如，如果 a4 想要开始活动，那么首先前提就是 V2 事件开始。所以 e[4]=ve[2]。

**最晚开始时间 l(i)**

表示活动 ai 的最晚开始时间，如果活动 ai 是由弧 <Vk,Vj> 表示，ai 的最晚开始时间的设定要保证 Vj 的最晚发生时间不拖后。所以，l[i]=Vl[j]-len<Vk,Vj>。

> 例如，如果

在得知以上四种统计数据后，就可以直接求得 AOE 网中关键路径上的所有的关键活动，方法是：

对于所有的边来说，如果它的最早开始时间等于最晚开始时间，称这条边所代表的活动为关键活动。由关键活动构成的路径为 **关键路径** 。

![关键路径](http://data.biancheng.net/uploads/allimg/170912/2-1F912155150E8.png)





### 迪杰斯特拉算法和弗洛伊德算法

在一个网（有权图）中，求一个顶点到另一个顶点的最短路径的计算方式有两种：

- 迪杰斯特拉（Dijkstra ）算法
- 弗洛伊德（Floyd）算法。

> 迪杰斯特拉算法计算的是有向网中的某个顶点到其余所有顶点的最短路径；
> 弗洛伊德算法计算的是任意两顶点之间的最短路径。

最短路径算法既适用于有向网，也同样适用于无向网。



#### 迪杰斯特拉算法

迪杰斯特拉算法计算的是从网中一个顶点到其它顶点之间的最短路径问题。

例如，用dijkstra算法计算在一个有向网中，从某个顶点（假设是V1）出发，到其他顶点之间最小路径时，可以直接到达的顶点用弧的权值去表示，无法直接到达的(V1到目标顶点之间没有弧存在)，则用无穷大(∞)表示。

其中，有权边中权值最小的边就是最短路径。例如V1到V2的边的权值是10，记录后，以最短路径的目标点 V2 为起始点，判断V2到其他顶点之间的距离（V1除外），如果对应的权值比之前记录的权值更小，则更新。

例如，V1到V3的距离是 ∞ ，但是V2到V3的距离是50，又因为V1到V2的距离是10，所以V1V2到V3的距离是60，比 ∞ 小，更新表格。之后，发现V1可以直接到V4，权值是40，所以之后从V4出发，判断到其他顶点之间的最短路径，继续更新，V1到V5的权值是100，然而，V4到V3的距离是20，V3到V5的距离是10，所以V1到V5的最短距离虽然转了几道，但可以算出V1-V4-V3-V5的距离是70，比V1-V5要小，所以更新。

如此往复，直到确定了V1与其他所有顶点的最短路径后，dijkstra 算法结束。

其实，无向网中的最短路径问题，也可以使用 dijkstra 算法解决，过程与上述一致。



迪杰斯特拉算法解决的是从网中的一个顶点到所有其它顶点之间的最短路径，算法整体的时间复杂度为 `O(n2)` 。但是如果需要求任意两顶点之间的最短路径，使用迪杰斯特拉算法虽然最终虽然也能解决问题，但是大材小用，相比之下使用弗洛伊德算法解决此类问题会更合适。



#### 弗洛伊德算法

迪杰斯特拉算法，主要解决从网（带权图）中某一顶点计算到其它顶点之间的最短路径问题。如果求有向网中每一对顶点之间的最短路径，使用迪杰斯特拉算法的解决思路是：以每一个顶点为源点，执行迪杰斯特拉算法。这样可以求得每一对顶点之间的最短路径，但是过于麻烦。

而弗洛伊德算法，相比于使用迪杰斯特拉算法在解决此问题上的时间复杂度虽然相同，都为O(n<sup>3</sup> )，但是弗洛伊德算法的实现形式更简单。

弗洛伊德的核心思想是：对于网中的任意两个顶点（例如顶点A 到顶点B）来说，之间的最短路径不外乎有2 种情况：
1. 直接从顶点A 到顶点B 的弧的权值为顶点A 到顶点B 的最短路径；
2. 从顶点A 开始，经过若干个顶点，最终达到顶点B，期间经过的弧的权值和为顶点A 到顶点B 的最短路径。

弗洛伊德算法的核心为：对于从顶点A 到顶点B 的最短路径，拿出网中所有的顶点进行如下判断： 
> Dis（A，K）+ Dis（K，B）< Dis（A，B）

其中，K 表示网中所有的顶点；Dis（A，B） 表示顶点A 到顶点B 的距离。

也就是说，拿出所有的顶点K，判断经过顶点K 是否存在一条可行路径比直达的路径的权值小，如果式子成立，说明确实存在一条权值更小的路径，此时只需要更新记录的权值和即可。

任意的两个顶点全部做以上的判断，最终遍历完成后记录的最终的权值即为对应顶点之间的最短路径。

步骤：
1. 记录顶点之间的权值
2. 依次遍历所有顶点，从某个顶点开始，作为中间点，看看对每对顶点之间的距离是否会更小，然后下一个顶点继续作为中间点，如此往复，知道所有顶点遍历完成。
3. 只有出度，没有入度的顶点可以直接忽略，因为它不会对其他顶点产生影响
4. 只有入度，没有出度的顶点同理


例如：
V1到V3的权值为 ∞，V1到V2的权值为10，V2到V3的权值为50，则（V1，V2）+（V2，V3）=60，比之前的值小，所以路径更短，则更新，如此往复，直到完成。





## 动态内存管理

### 动态内存管理

本章重点解决的问题是

- 对于用户向系统提出的申请空间的请求，系统如何分配内存？
- 当用户不在使用之前申请的内存空间后，系统又如何回收？

这里的用户，不是普通意义上的用户，可能是一个普通的变量，一个应用程序，一个命令等等。只要是向系统发出内存申请的，都可以称之为用户。



#### 占用块和空闲块

对于计算机中的内存来说，已经分配给用户的的内存区统称为 **占用块**；还未分配出去的内存区统称为 **空闲块** 或者 **可利用空间块**。



#### 系统的内存管理

对于初始状态下的内存来说，整个空间都是一个空闲块（在编译程序中称为“堆”）。但是随着不同的用户不断地提出存储请求，系统依次分配。

整个内存区就会分割成两个大部分：

- 低地址区域会产生很多占用块
- 高地址区域还是空闲块

动态分配过程中的内存状态是，内存地址逐渐增大。当某些用户运行结束，所占用的内存区就成了空闲块，这些空闲块大小不一，此时，就形成了占用块和空闲块交错的状态。

所以，当后续用户请求分配内存时，系统有两种分配方式：

1. 系统继续利用高地址区域的连续空闲块分配给用户，不去理会之前分配给用户的内存区域的状态。直到分配无法进行，也就是高地址的空闲块不能满足用户的需求时，系统才会去回收之前的空闲块，重新组织继续分配；
2. 当用户运行一结束，系统马上将其所占空间进行回收。当有新的用户请求分配内存时，系统遍历所有的空闲块，从中找出一个合适的空闲块分配给用户。

> 合适的空闲块指的是能够满足用户要求的空闲块，具体的查找方式有多种，后续会介绍。



#### 可利用空间表

当采用第 2 种方式时，系统需要建立一张记录所有空闲块信息的表。表的形式有两种：**目录表** 和 **链表** 。

![目录表和链表](http://data.biancheng.net/uploads/allimg/170928/2-1F92P94631260.png)

**目录表**：表中每一行代表一个空闲块，由三部分组成：

- 初始地址：  记录每个空闲块的起始地址。
- 空闲块大小：  记录每个空闲块的内存大小。
- 使用情况：  记录每个空闲块是否存储被占用的状态。

**链表**：

表中每个结点代表一个空闲块，每个结点中需要记录空闲块的使用情况、大小和连接下一个空闲块的指针域 (由于链表中有指针的存在，所以结点中不需要记录各内存块的起始地址) 。



系统在不同的环境中运行，根据用户申请空间的不同，存储空闲块的可利用空间表有以下不同的结构：

1. 如果每次用户请求的存储空间大小相同，对于此类系统中的内存来说，在用户运行初期就将整个内存存储块按照所需大小进行分割，然后通过链表链接。当用户申请空间时，从链表中摘除一个结点归其使用；用完后再链接到可利用空间表上。
2. 每次如果用户申请的都是若干种大小规格的存储空间，针对这种情况可以建立若干个可利用空间表，每一个链表中的结点大小相同。当用户申请某一规格大小的存储空间时，就从对应的链表中摘除一个结点供其使用；用完后链接到相同规格大小的链表中。
3. 用户申请的内存的大小不固定，所以造成系统分配的内存块的大小也不确定，回收时，链接到可利用空间表中每个结点的大小也各不一样。

> 第 2 种情况下容易面临的问题是：如果同用户申请空间大小相同的链表中没有结点时，就需要找结点更大的链表，从中取出一个结点，一部分给用户使用，剩余部分插入到相应大小的链表中；回收时，将释放的空闲块插入到大小相同的链表中去。如果没有比用户申请的内存空间相等甚至更大的结点时，就需要系统重新组织一些小的连续空间，然后给用户使用。

#### 分配存储空间的方式

通常情况下系统中的可利用空间表是第 3 种情况。如图 (C) 所示。由于链表中各结点的大小不一，在用户申请内存空间时，就需要从可利用空间表中找出一个合适的结点，有三种查找的方法：

- **首次拟合法**：  在可利用空间表中从头开始依次遍历，将找到的第一个内存不小于用户申请空间的结点分配给用户，剩余空间仍留在链表中；回收时只要将释放的空闲块插入在链表的表头即可。
- **最佳拟合法**：  和首次拟合法不同，最佳拟合法是选择一块内存空间不小于用户申请空间，但是却最接近的一个结点分配给用户。为了实现这个方法，首先要将链表中的各个结点按照存储空间的大小进行从小到大排序，由此，在遍历的过程中只需要找到第一块大于用户申请空间的结点即可进行分配；用户运行完成后，需要将空闲块根据其自身的大小插入到链表的相应位置。
- **最差拟合法**：  和最佳拟合法正好相反，该方法是在不小于用户申请空间的所有结点中，筛选出存储空间最大的结点，从该结点的内存空间中提取出相应的空间给用户使用。为了实现这一方法，可以在开始前先将可利用空间表中的结点按照存储空间大小从大到小进行排序，第一个结点自然就是最大的结点。回收空间时，同样将释放的空闲块插入到相应的位置上。

以上三种方法各有所长：

- 最佳拟合法由于每次分配相差不大的结点给用户使用，所以会生成很多存储空间特别小的结点，以至于根本无法使用，使用过程中，链表中的结点存储大小发生两极分化，
- 大的很大，小的很小。该方法适用于申请内存大小范围较广的系统
- 最差拟合法，由于每次都是从存储空间最大的结点中分配给用户空间，所以链表中的结点大小不会起伏太大。依次适用于申请分配内存空间较窄的系统。
- 首次拟合法每次都是随机分配。在不清楚用户申请空间大小的情况下，使用该方法分配空间。

同时，三种方法中，最佳拟合法相比于其它两种方式，无论是分配过程还是回收过程，都需要遍历链表，所有最费时间。



#### 空间分配与回收过程产生的问题

无论使用以上三种分配方式中的哪一种，最终内存空间都会成为一个一个特别小的内存空间，对于用户申请的空间的需求，单独拿出任何一个结点都不能够满足。

但是并不是说整个内存空间就不够用户使用。在这种情况下，就需要系统在回收的过程考虑将地址相邻的空闲块合并。

> 合并的具体方法会在后面章节详细介绍。





### 边界标识法

解决系统中内存碎片过多而无法使用的方法——边界标识法

在使用边界标识法的系统管理内存时，可利用空间表中的结点的构成

![结构构成](http://data.biancheng.net/uploads/allimg/170928/2-1F92Q0092A01.png)

每个结点中包含 3 个区域，head 域、foot 域 和 space 域：

- **space 域**  表示为该内存块的大小，它的大小通过 head 域中的 size 值表示。
- **head 域**  中包含有 4 部分：
	- llink 和 rlink 分别表示指向当前内存块结点的直接前驱和直接后继。
	- tag 值用于标记当前内存块的状态，是占用块（用 1 表示）还是空闲块（用 0 表示）。
	- size 用于记录该内存块的存储大小。
- **foot 域**  中包含有 2 部分：
	- uplink 是指针域，用于指向内存块本身，通过 uplink 就可以获取该内存块所在内存的首地址。
	- tag 同 head 域中的 tag 相同，都是记录内存块状态的。

注意：head 域和 foot 域在本节中都假设只占用当前存储块的 1 个存储单位的空间，对于该结点整个存储空间来说，可以忽略不计。
也就是说，在可利用空间表中，知道下一个结点的首地址，该值减 1 就可以找到当前结点的 foot 域。

使用边界标识法的可利用空间表本身是双向循环链表，每个内存块结点都有指向前驱和后继结点的指针域。

通过以上介绍的结点结构构建的可利用空间表中，任何一个结点都可以作为该链表的头结点（用 pav 表示头结点），当头结点为 NULL 时，即可利用空间表为空，无法继续分配空间。



#### 分配算法

当用户申请空间时，系统可以采用 3 种分配方法中的任何一种。但在不断地分配的过程中，会产生一些容量极小以至无法利用的空闲块，这些不断生成的小内存块就会减慢遍历分配的速度。

3 种分配方法分别为： **首部拟合法** 、 **最佳拟合法** 和 **最差拟合法** 。

针对这种情况，解决的措施是：
1. 选定一个常量 e，每次分配空间时，判断当前内存块向用户分配空间后，如果剩余部分的容量比 e 小，则将整个内存块全部分配给用户。
2. 采用头部拟合法进行分配时，如果每次都从 pav 指向的结点开始遍历，在若干次后，会出现存储量小的结点密集地分布在 pav 结点附近的情况，严重影响遍历的时间。解决办法就是：在每次分配空间后，让 pav 指针指向该分配空间结点的后继结点，然后从新的 pav 指向的结点开始下一次的分配。



#### 回收算法

在用户活动完成，系统需要立即回收被用户占用的存储空间，以备新的用户使用。回收算法中需要解决的问题是：在若干次分配操作后，可利用空间块中会产生很多存储空间很小以致无法使用的空闲块。但是经过回收用户释放的空间后，可利用空间表中可能含有地址相邻的空闲块，回收算法需要将这些地址相邻的空闲块合并为大的空闲块供新的用户使用。

合并空闲块有 3 种情况：

- 该空闲块的左边有相邻的空闲块可以进行合并；
- 该空闲块的右边用相邻的空闲块可以进行合并；
- 该空闲块的左右两侧都有相邻的空闲块可以进行合并；

> 判断当前空闲块左右两侧是否为空闲块的方法是
>
> 对于当前空闲块 p 
>
> - p-1 就是相邻的低地址处的空闲块的 foot 域，如果 foot 域中的 tag 值为 0 ，表明其为空闲块；
> - p+p->size 表示的是高地址处的块的 head 域，如果 head 域中的 tag 值为 0，表明其为空闲块。

- 如果当前空闲块的左右两侧都不是空闲块，而是占用块
	此种情况下只需要将新的空闲块按照相应的规则（头部拟合法随意插入，其它两种方法在对应位置插入）插入到可利用空间表中即可。

- 如果该空闲块的左侧相邻的块为空闲块，右侧为占用块
	只需要更改左侧空闲块中的 size 的大小，并重新设置左侧空闲块的 foot 域即可

- 如果用户释放的内存块的相邻左侧为占用块，右侧为空闲块
	将用户释放掉的存储块替换掉右侧的空闲块，同时更改存储块的 size 和右侧空闲块的 uplink 指针的指向

- 如果当前用户释放掉的空闲块，物理位置上相邻的左右两侧的内存块全部为空闲块
	需要将 3 个空闲块合并为一个更大的块，操作的过程为：更新左侧空闲块的 size 的值，同时在可利用空间表中摘除右侧空闲块，最后更新合并后的大的空闲块的 foot 域。

此情况和只有左侧有空闲块的情况雷同，唯一的不同点是多了一步摘除右侧相邻空闲块结点的操作。





### 伙伴系统

前面介绍了系统在分配与回收存储空间时采取的边界标识法。本节再介绍一种管理存储空间的方法： **伙伴系统** 。

伙伴系统本身是一种动态管理内存的方法，和边界标识法的区别是： **使用伙伴系统管理的存储空间，无论是空闲块还是占用块，大小都是 2 的 n 次幂（n 为正整数）** 。

例如，系统中整个存储空间为 2<sup>m</sup> 个字。那么在进行若干次分配与回收后，可利用空间表中只可能包含空间大小为：2<sup>0</sup>、2<sup>1</sup>、2<sup>2</sup>、…、2<sup>m</sup> 的空闲块。

> 字是一种计量单位，由若干个字节构成，不同位数的机器，字所包含的字节数不同。例如，8 位机中一个字由 1 个字节组成；16 位机器一个字由 2 个字节组成。



#### 可利用空间表中结点构成

伙伴系统中可利用空间表中的结点构成如图所示：

![结点构成](http://data.biancheng.net/uploads/allimg/170928/2-1F92Q03525355.png)

**header 域表示为头部结点** ，由 4 部分构成：

- llink 和 rlink 为结点类型的指针域，分别用于指向直接前驱和直接后继结点。
- tag 值：用于标记内存块的状态，是占用块（用 1 表示）还是空闲块（用 0 表示）
- kval ：记录该存储块的容量。由于系统中各存储块都是 2 的 m 幂次方，所以 kval 记录 m 的值。

```c
typedef struct WORD_b{
    struct WORD_b *llink;//指向直接前驱
    int tag;//记录该块是占用块还是空闲块
    int kval;//记录该存储块容量大小为2的多少次幂
    struct WORD_b *rlink;//指向直接后继
    OtherType other;//记录结点的其它信息
}WORD_b,head;
```

在伙伴系统中，由于系统会不断地接受用户的内存申请的请求，所以会产生很多大小不同但是都是容量为 2<sup>m</sup> 的内存块，所以为了在分配的时候查找方便，系统采用将大小相同的各自建立一个链表。对于初始容量为 2<sup>m</sup> 的一整块存储空间来说，形成的链表就有可能有 m+1 个，为了更好的对这些链表进行管理，系统将这 m+1 个链表的表头存储在数组中，就类似于邻接表的结构，，如图 2。

![伙伴系统的初始状态](http://data.biancheng.net/uploads/allimg/170928/2-1F92Q04021135.png)

可利用空间表的代码表示为：

```c
#define m 16//设定m的初始值
typedef struct HeadNode {
    int nodesize;//记录该链表中存储的空闲块的大小
    WORD_b * first;//相当于链表中的next指针的作用
}FreeList[m+1];//一维数组
```



#### 分配算法

伙伴系统的分配算法很简单。假设用户向系统申请大小为 n 的存储空间，若 2<sup>k-1</sup> < n <= 2<sup>k</sup>，此时就需要查看可利用空间表中大小为 2<sup>k</sup> 的链表中有没有可利用的空间结点：

- 如果该链表不为 NULL，可以直接采用头插法从头部取出一个结点，提供给用户使用；
- 如果大小为 2<sup>k</sup> 的链表为 NULL，就需要依次查看比 2<sup>k</sup> 大的链表，找到后从链表中删除，截取相应大小的空间给用户使用，剩余的空间，根据大小插入到相应的链表中。

例如，用户向系统申请一块大小为 7 个字的空间，而系统总的内存为 2<sup>4</sup> 个字，则此时按照伙伴系统的分配算法得出：2<sup>2</sup> < 7 < 2<sup>3</sup>，所以此时应查看可利用空间表中大小为 2<sup>3</sup> 的链表中是否有空闲结点：

- 如果有，则从该链表中摘除一个结点，直接分配给用户使用；
- 如果没有，则需依次查看比 2<sup>3</sup> 大的各个链表中是否有空闲结点。假设，在大小 2<sup>4</sup> 的链表中有空闲块，则摘除该空闲块，分配给用户 2<sup>3</sup> 个字的空间，剩余 2<sup>3</sup> 个字，该剩余的空闲块添加到大小为 2<sup>3</sup> 的链表中。

![伙伴系统分配过程](http://data.biancheng.net/uploads/allimg/170928/2-1F92Q043552O.png)

左边是分配前，右边是分配后



#### 回收算法总结

无论使用什么内存管理机制，在内存回收的问题上都会面临一个共同的问题： **如何把回收的内存进行有效地整合，伙伴系统也不例外** 。

当用户申请的内存块不再使用时，系统需要将这部分存储块回收，回收时需要判断是否可以和其它的空闲块进行合并。

在寻找合并对象时，伙伴系统和边界标识法不同，在伙伴系统中每一个存储块都有各自的 *伙伴* ，当用户释放存储块时只需要判断该内存块的伙伴是否为空闲块，如果是则将其合并，然后合并的新的空闲块还需要同其伙伴进行判断整合。反之直接将存储块根据大小插入到可利用空间表中即可。

判断一个存储块的伙伴的位置时，采用的方法为：如果该存储块的起始地址为 p，大小为 2<sup>k</sup>，则其伙伴所在的起始地址为：

![img](http://data.biancheng.net/uploads/allimg/170928/2-1F92Q0444M94.png)

例如，当大小为 2<sup>8</sup> ，起始地址为 512 的伙伴块的起始地址的计算方式为：
由于 512 MOD 2<sup>9</sup>=0，所以，512+2<sup>8</sup>=768，及如果该存储块回收时，只需要查看起始地址为 768 的存储块的状态，如果是空闲块则两者合并，反之直接将回收的释放块链接到大小为 2<sup>8</sup> 的链表中。



使用伙伴系统进行存储空间的管理过程中，在用户申请空间时，由于大小不同的空闲块处于不同的链表中，所以分配完成的速度会更快，算法相对简单。

回收存储空间时，对于空闲块的合并，不是取决于该空闲块的相邻位置的块的状态；而是完全取决于其伙伴块。所以即使其相邻位置的存储块时空闲块，但是由于两者不是伙伴的关系，所以也不会合并。这也就是该系统的缺点之一：由于在合并时只考虑伙伴，所以容易产生存储的碎片。





### 系统垃圾回收机制

通过前几节对可利用空间表进行动态存储管理的介绍，运行机制可以概括为： **当用户发出申请空间的请求后，系统向用户分配内存；用户运行结束释放存储空间后，系统回收内存** 。这两部操作都是在用户给出明确的指令后，系统对存储空间进行有效地分配和回收。

但是在实际使用过程中，有时会因为用户申请了空间，但是在使用完成后没有向系统发出释放的指令，导致存储空间既没有被使用也没有被回收，变为了 **无用单元** 或者会产生 **悬挂访问** 的问题。

什么是无用单元？简单来讲， **无用单元是一块用户不再使用，但是系统无法回收的存储空间** 。
例如在C语言中，用户可以通过 malloc 和 free 两个功能函数来动态申请和释放存储空间。当用户使用 malloc 申请的空间使用完成后，没有使用 free 函数进行释放，那么该空间就会成为 **无用单元** 。

悬挂访问也很好理解：假设使用 malloc 申请了一块存储空间，有多个指针同时指向这块空间，当其中一个指针完成使命后，私自将该存储空间使用 free 释放掉，导致其他指针处于悬空状态，如果释放掉的空间被再分配后，再通过之前的指针访问，就会造成错误。数据结构中称这种访问为 **悬挂访问** 。

在含有共享子表的广义表中，也可能会产生无用单元。

假设L1、L2 和 L3 分别为三个广义表的表头指针，L4 为 L1 和 L2 所共享，L3 是 L2 的子表，L5 为 L1、L2 和 L3 三个广义表所共享。

在此基础上，假设表 L1 不再使用，而 L2 和 L3 还在使用，若释放表 L1，L1 中的所有结点所占的存储空间都会被释放掉，L2 和 L3 中由于同样包含 L1 中的结点，两个表会被破坏，某些指针会产生悬挂访问的错误；

而如果 L1 表使用完成后不及时释放，L1 中独自占用的结点由于未被释放，系统也不会回收，就会成为无用单元。 

解决存储空间可能成为无用单元或者产生悬挂访问的方法有两个：

1. 每个申请的存储空间设置一个计数域，这个计数域记录的是指向该存储空间的指针数目，只有当计数域的值为 0 时，该存储空间才会被释放。
2. 在程序运行时，所有的存储空间无论是处于使用还是空闲的状态，一律不回收，当系统中的可利用空间表为空时，将程序中断，对当前不在使用状态的存储空间一律回收，全部链接成一个新的可利用空间表后，程序继续执行。

第二种方法中，在程序运行过程中很难找出此时哪些存储空间是空闲的。解决这个问题的办法是： **找当前正在被占用的存储空间，只需要从当前正在工作的指针变量出发依次遍历，就可以找到当前正在被占用的存储空间，剩余的自然就是此时处于空闲状态的存储空间** 。



如果想使用第二种方式，可以分为两步进行：

- 对所有当前正在使用的存储空间加上被占用的标记（对于广义表来说，可以在每个结点结构的基础上，添加一个 mark 的标志域。在初始状态下，所有的存储空间全部标志为 0，被占用时标记为 1）；
- 依次遍历所有的存储空间，将所有标记为 0 的存储空间链接成一个新的可利用空间表。



对正在被占用的存储空间进行标记的方法有三种：

- 从当前正在工作的指针变量开始，采用递归算法依次将所有表中的存储结点中的标志域全部设置为 1；
- 第一种方法中使用递归算法实现的遍历。而递归底层使用的栈的存储结构，所以也可以直接使用栈的方式进行遍历；
- 以上两种方法都是使用栈结构来记录遍历时指针所走的路径，便于在后期可以沿原路返回。所以第三种方式就是使用其他的方法代替栈的作用。



递归和非递归方式在前面章节做过详细介绍，第三种实现方式中代替栈的方法是： **添加三个指针，p 指针指向当前遍历的结点，t 指针永远指向 p 的父结点，q 指向 p 结点的表头或者表尾结点** 。 在遍历过程遵循以下原则：

当 q 指针指向 p 的表头结点时，可能出现 3 种情况：

- p 结点的表头结点只是一个元素结点，没有表头或者表尾，这时只需要对该表头结点打上标记后即 q 指向 p 的表尾；
- p 结点的表头结点是空表或者是已经做过标记的子表，这时直接令 q 指针指向 p 结点的表尾即可；
- p 结点的表头是未添加标记的子表，这时就需要遍历子表，令 p 指向 q，q 指向 q 的表头结点。同时 t 指针相应地往下移动，但是在移动之前需要记录 t 指针的移动轨迹。记录的方法就是令 p 结点的 hp 域指向 t，同时设置 tag 值为 0。



当 q 指针指向 p 的表尾结点时，可能出现 2 种情况：

- p 指针的表尾是未加标记的子表，就需要遍历该子表，和之前的类似，令 p 指针和 t 指针做相应的移动，在移动之前记录 t 指针的移动路径，方法是：用 p 结点的 tp 域指向 t 结点，然后在 t 指向 p，p 指向 q。
- p 指针的表尾如果是空表或者已经做过标记的结点，这时 p 结点和 t 结点都回退到上一个位置。

> 由于 t 结点的回退路径分别记录在结点的 hp 域或者 tp 域中，在回退时需要根据 tag 的值来判断：如果 tag 值为 0 ，t 结点通过指向自身 hp 域的结点进行回退；反之，t 结点通过指向其 tp 域的结点进行回退。



无用单元的收集可以采用以上 3 中算法中任何一种。无论使用哪种算法，无用单元收集本身都是很费时间的，所以无用单元的收集不适用于实时处理的情况中使用。





### 内存紧缩(内存碎片化处理)

前边介绍的有关动态内存管理的方法，无论是边界标识法还是伙伴系统，但是以将空闲的存储空间链接成一个链表，即可利用空间表，对存储空间进行分配和回收。

本节介绍另外一种动态内存管理的方法，使用这种方式在整个内存管理过程中，不管哪个时间段，所有未被占用的空间都是地址连续的存储区。

这些地址连续的未被占用的存储区在编译程序中称为 **堆**。



#### 分配内存空间

在分配内存空间时，每次都从可利用空间中选择最低（或者最高）的地址进行分配。具体的实现办法为：设置一个指针（称为 *堆指针* ），每次用户申请存储空间时，都是堆的最低（或者最高）地址进行分配。假设当用户申请 N 个单位的存储空间时，堆指针向高地址（或者低地址）移动 N 个存储单位，这 N 个存储单位即为分配给用户使用的空闲块，空闲块的起始地址为堆指针移动之前所在的地址。

![分配内存空间](http://data.biancheng.net/uploads/allimg/171008/2-1G00Q0043Q00.png)



#### 回收算法

由于系统中的可利用空间始终都是一个连续的存储空间，所以回收时必须将用户释放的存储块合并到这个堆上才能够重新使用。

存储紧缩有两种做法：

1. 一旦用户释放所占空间就立即进行回收紧缩；
2. 在程序执行过程中不立即回收用户释放的存储块，而是等到可利用空间不够分配或者堆指针指向了可利用存储区的最高地址时才进行存储紧缩。


具体的实现过程是：
1. 计算占用块的新地址。设立两个指针随巡查向前移动，分别用于指示占用块在紧缩之前和之后的原地址和新地址。因此，在每个占用块的第一个存储单位中，除了存储该占用块的大小和标志域之外，还需要新增一个新地址域，用于存储占用块在紧缩后应有的新地址，即建立一张新、旧地址的对照表。
2. 修改用户的初始变量表，保证在进行存储紧缩后，用户还能找到自己的占用块。
3. 检查每个占用块中存储的数据。如果有指向其它存储块的指针，则需作相应修改。
4. 将所有占用块迁移到新地址去，即进行数据的传递。
5. 最后，还要将堆指针赋以新的值。


存储紧缩较之无用单元收集更为复杂，是一个系统的操作，如果不是非不得已不建议使用。








## 算法

### 查找算法

#### 概念

在日常生活中，几乎每天都要进行一些查找的工作，在电话簿中查阅某个人的电话号码；在电脑的文件夹中查找某个具体的文件等等。本节主要介绍用于查找操作的数据结构—— **查找表** 。

**查找表 是由同一类型的数据元素构成的集合** 。例如电话号码簿和字典都可以看作是一张查找表。

一般对于查找表有以下几种操作：

- 在查找表中查找某个具体的数据元素；
- 在查找表中插入数据元素；
- 从查找表中删除数据元素；



**静态查找表和动态查找表**

- 在查找表中只做查找操作，而不改动表中数据元素，称此类查找表为 **静态查找表** ；
- 反之，在查找表中做查找操作的同时进行插入数据或者删除数据的操作，称此类表为 **动态查找表** 。



**关键字**

在查找表查找某个特定元素时，前提是需要知道这个元素的一些属性。例如，每个人上学的时候都会有自己唯一的学号，因为你的姓名、年龄都有可能和其他人是重复的，唯独学号不会重复。而学生具有的这些属性（学号、姓名、年龄等）都可以称为 **关键字** 。

关键字又细分为 **主关键字** 和 **次关键字** 。

- 若某个关键字可以唯一地识别一个数据元素时，称这个关键字为 **主关键字** ，例如学生的学号就具有唯一性。
- 像学生姓名、年龄这类的关键字，由于不具有唯一性，称为 **次关键字** 。



**如何进行查找**

*不同的查找表，其使用的查找方法是不同的* 。 

例如每个人都有属于自己的朋友圈，都有自己的电话簿，电话簿中数据的排序方式是多种多样的，有的是按照姓名的首字母进行排序，这种情况在查找时，就可以根据被查找元素的首字母进行顺序查找；有的是按照类别（亲朋好友）进行排序。在查找时，就需要根据被查找元素本身的类别关键字进行排序。

具体的查找方法需要根据实际应用中具体情况而定。

本章从 静态查找表、动态查找表 和 哈希表 的角度具体分析针对不同的查找表可供选择的查找算法。


#### 顺序查找

静态查找表既可以使用顺序表表示，也可以使用链表结构表示。虽然一个是数组、一个链表，但两者在做查找操作时，基本上大同小异。



顺序查找的实现：

静态查找表用顺序存储结构表示时，顺序查找的查找过程为：从表中的最后一个数据元素开始，逐个同记录的关键字做比较，如果匹配成功，则查找成功；反之，如果直到表中第一个关键字查找完也没有成功匹配，则查找失败。

同时，在程序中初始化创建查找表时，由于是顺序存储，所以将所有的数据元素存储在数组中，但是把第一个位置留给了用户用于查找的关键字。例如，在顺序表{1,2,3,4,5,6}中查找数据元素值为 7 的元素，则添加后的顺序表为： {7(监视哨位置) ，1,2,3,4,5,6}

顺序表的一端添加用户用于搜索的关键字，称作 **监视哨** 。

> 监视哨的位置放在任意一段即可，也就是说放在元素6的后面也是可以的，但是查找顺序需由逆向改为顺序。

放置好监视哨之后，顺序表遍历从没有监视哨的一端依次进行，如果查找表中有用户需要的数据，则程序输出该位置；反之，程序会运行至监视哨，此时匹配成功，程序停止运行，但是结果是查找失败。





#### 二分查找

折半查找，也叫二分查找，在某些情况下比顺序查找效率更高。但该算法的前提是静态查找表的数据必须是有序的。

例如，在{1,3,2,4,5}这个查找表使用折半查找算法查找数据之前，需要首先对该表中的数据按照所查的关键字进行排序:{1,2,3,4,5}

在折半查找之前对查找表按照所查的关键字进行排序的意思是：若查找表中存储的数据元素含有多个关键字时，使用哪种关键字做折半查找，就需要提前以该关键字对所有数据进行排序。

排序完成之后，指针low和high分别指向查找表的第一个关键字和最后一个关键字，mid指向low和high中间位置的关键字。在查找的过程中每次都同 mid 指向的关键字进行比较，由于整个表中的数据是有序的，因此在比较之后就可以知道要查找的关键字的大致位置。

用个大一点的表来表示：{0,1,2,3,4,5,6,7,8,9,10}

例如low指向0，high指向10，mid则指向5。查找2的时候，首先与5进行比较，因为2<5, 而且查找表是按升序排列的，所以可以锁定在low和mid之间的区域进行查找。

再次遍历时需要更新high指针和mid指针的位置，这时，high指针指向4，mid指针仍然指向中间数2，发现mid指向的关键字正是2，查找结束。

> 在做查找的过程中，如果 low 指针和 high 指针的中间位置在计算时位于两个关键字中间，即求得 mid 的位置不是整数，需要统一做取整操作。

折半查找的运行过程可以用二叉树来描述，这棵树通常称为 **判定树** 。

在查找表中各个关键字被查找概率相同的情况下，折半查找的平均查找长度为：`ASL = log2(n+1) – 1`

通过比较折半查找的平均查找长度，同前面介绍的顺序查找相对比，明显折半查找的效率要高。但是折半查找算法只适用于有序表，同时仅限于查找表用顺序存储结构表示。

当查找表使用链式存储结构表示时，折半查找算法无法有效地进行比较操作（排序和查找操作的实现都异常繁琐）。





#### 分块查找(索引顺序查找)

本节介绍一种在顺序查找的基础上对其进行改进的算法—— **分块查找算法** 。

分块查找，也叫索引顺序查找，算法实现除了需要查找表本身之外，还需要根据查找表建立一个索引表。

先创建一个表，{{11,2,5,8,9},{17,16,18,22,33},{99,66,77,88,55}} 。

| 最大关键字 | 起始地址 |
| ---------- | -------- |
| 11         | 0        |
| 33         | 5        |
| 99         | 10       |

该查找表中共15个查找关键字，将其平均分为3个子表，对每个子表建立一个索引，索引包含两部分内容： **最大关键字** 和 **第一个关键字在总表中的位置(子表起始位置)** 。

建立的索引表要求按照关键字进行升序排序，查找表要么整体有序，要么分块有序。

**分块有序** 指的是第二个子表中所有关键字都要大于第一个子表中的最大关键字，第三个子表的所有关键字都要大于第二个子表中的最大关键字，依次类推。

块（子表）中各关键字的具体顺序，根据各自可能会被查找到的概率而定。如果各关键字被查找到的概率是相等的，那么可以随机存放；否则可按照被查找概率进行降序排序，以提高算法运行效率。



**分块查找的具体实现**

所有前期准备工作完成后，开始在此基础上进行分块查找。分块查找的过程分为两步进行：
1. 确定要查找的关键字可能存在的具体块（子表）；
2. 在具体的块中进行顺序查找。

以上面的查找表为例，假设要查找关键字18 的具体位置。首先将18 依次和索引表中各最大关键字进行比较，因为 11 < 18 < 33，所以可以确定18 如果存在，肯定在第二个子表中。

由于索引表中显示第二子表的起始位置在查找表的索引为 5 的位置上，所以从该位置开始进行顺序查找，一直查找到该子表最后一个关键字（一般将查找表进行等分，具体子表个数根据实际情况而定）。结果在 index 为 7 的位置上确定该关键字即为所找。

提示：在第一步确定块（子表）时，由于索引表中按照关键字有序，所有可以采用折半查找算法。而在第二步中，由于各子表中关键字没有严格要求有序，所以只能采用顺序查找的方式。



分块查找算法的运行效率受两部分影响： **查找块的操作** 和 **块内查找的操作** 。

- 查找块的操作可以采用顺序查找，也可以采用折半查找（更优）
- 块内查找的操作采用顺序查找的方式。
- 相比于折半查找，分块查找时间效率上更低一些；
- 相比于顺序查找，由于在子表中进行，比较的子表个数会不同程度的减少，所有分块查找算法会更优。
- 总体来说，分块查找算法的效率介于顺序查找和折半查找之间。





#### 静态树表查找

前面章节所介绍的有关在 *静态查找表* 中对特定关键字进行 *顺序查找* 、 *折半查找* 或者 *分块查找* ，都是在查找表中各关键字被查找概率相同的前提下进行的。

例如查找表中有n 个关键字，表中每个关键字被查找的概率都是1/n。 **在等概率的情况，使用折半查找算法的性能最优** 。

而在某些情况下，查找表中各关键字被查找的概率是不同的。例如水果商店中有很多种水果，对于不同的顾客来说，由于口味不同，各种水果可能被选择的概率是不同的。假设该顾客喜吃酸，那么相对于苹果和橘子，选择橘子的概率肯定要更高一些。

在查找表中各关键字查找概率不相同的情况下，对于使用折半查找算法，按照之前的方式进行，其查找的效率并不一定是最优的。

例如，某查找表中有5 个关键字，各关键字被查找到的概率分别为：0.1，0.2，0.1，0.4，0.2（全部关键字被查找概率和为1 ），则根据之前介绍的折半查找算法，建立相应的判定树为（树中各关键字用概率表示）：

```
0.1(Root) --> 0.1L --> 0.2
0.1(Root) --> 0.4R --> 0.2
```

折半查找查找成功时的平均查找长度的计算方式为：
`ASL = 判定树中各结点的查找概率 * 所在层次`

所以该平均查找长度为：
`ASL=0.1*1 + 0.1*2 + 0.4*2 + 0.2*3 + 0.2*3 = 2.3`

由于各关键字被查找的概率是不相同的，所以若在查找时遵循被查找关键字先和查找概率大的关键字进行比对，建立的判定树为：
```
0.4(Root) --> 0.2L --> 0.1
0.4(Root) --> 0.2R --> 0.1
```

对应的平均查找长度为：
`ASL = 0.4*1 + 0.2*2 + 0.2*2 + 0.1*3 + 0.1*3 = 1.8`

后者折半查找的效率要比前者高，所以在查找表中各关键字查找概率不同时，要考虑建立一棵查找性能最佳的判定树。若在只考虑查找成功的情况下，描述查找过程的判定树其带权路径长度之和（用PH 表示）最小时，查找性能最优，称该二叉树为 **静态最优查找树** 。

带权路径之和的计算公式为：`PH = 所有结点所在的层次数 * 每个结点对应的概率值` 。

但是由于构造最优查找树花费的时间代价较高，而且有一种构造方式创建的判定树的查找性能同最优查找树仅差1% - 2%，称这种极度接近于最优查找树的二叉树为 **次优查找树** 。



#### 次优查找树

首先取出查找表中每个关键字及其对应的权值，采用如下公式计算出每个关键字对应的一个值：

![次优查找树](https://www.zhihu.com/equation?tex=%5CDelta+P_%7Bi%7D+%3D+%7C%5Csum_%7Bj%3Di%2B1%7D%5E%7Bh%7D%7B%5Comega+_%7Bj%7D%7D+-+%5Csum_%7Bj%3Dl%7D%5E%7Bi-1%7D%7B%5Comega+_%7Bj%7D%7D%7C)

其中w<sub>j</sub> 表示每个关键字的权值（被查找到的概率），h 表示关键字的个数。

表中有多少关键字，就会有多少个△P<sub>i</sub> ，取其中最小的做为次优查找树的根结点，然后将表中关键字从第i 个关键字的位置分成两部分，分别作为该根结点的左子树和右子树。同理，左子树和右子树也这么处理，直到最后构成次优查找树完成。





#### 二叉排序树（二叉查找树）

前几节介绍的都是有关静态查找表的相关知识，从本节开始介绍另外一种查找表—— **动态查找表** 。

动态查找表中做查找操作时，若查找成功可以对其进行删除；如果查找失败，即表中无该关键字，可以将该关键字插入到表中。

动态查找表的表示方式有多种，本节介绍一种使用树结构表示动态查找表的实现方法—— **二叉排序树** （又称为“二叉查找树”）。



二叉排序树要么是空二叉树，要么具有如下特点：

- 二叉排序树中，如果其根结点有左子树，那么左子树上所有结点的值都小于根结点的值；
- 二叉排序树中，如果其根结点有右子树，那么右子树上所有结点的值都大于根结点的值；
- 二叉排序树的左右子树也要求都是二叉排序树；

![二叉排序树](http://data.biancheng.net/uploads/allimg/171016/2-1G01615222R04.png)



**使用二叉排序树查找关键字**

二叉排序树中查找某关键字时，查找过程类似于次优二叉树，在二叉排序树不为空树的前提下，首先将被查找的值，同树的根结点进行比较，会有 3 种不同的结果：

- 如果相等，查找成功；
- 如果比较结果为根结点的关键字值较大，则说明该关键字可能存在其左子树中；
- 如果比较结果为根结点的关键字值较小，则说明该关键字可能存在其右子树中；



**二叉排序树中插入关键字**

二叉排序树本身是动态查找表的一种表示形式，有时会在查找过程中插入或者删除表中元素，当因为查找失败而需要插入数据元素时，该数据元素的插入位置一定位于二叉排序树的叶子结点，并且一定是查找失败时访问的最后一个结点的左孩子或者右孩子。

例如，在图中的二叉排序树中做查找关键字 1 的操作，当查找到关键字 3 所在的叶子结点时，判断出表中没有该关键字，此时关键字 1 的插入位置为关键字 3 的左孩子。

通过使用二叉排序树对动态查找表做查找和插入的操作，同时在中序遍历二叉排序树时，可以得到有关所有关键字的一个有序的序列。

例如，假设原二叉排序树为空树，在对动态查找表 {3，5，7，2，1} 做查找以及插入操作时，可以构建出一个含有表中所有关键字的二叉排序树，过程如图所示:

![二叉排序树插入过程](http://data.biancheng.net/uploads/allimg/171016/2-1G016152600A4.png)

通过不断的查找和插入操作，最终构建的二叉排序树如图 2（5） 所示。当使用中序遍历算法遍历二叉排序树时，得到的序列为：1 2 3 5 7 ，为有序序列。

**一个无序序列可以通过构建一棵二叉排序树，从而变成一个有序序列** 。



**二叉排序树中删除关键字**

在查找过程中，如果在使用二叉排序树表示的动态查找表中删除某个数据元素时，需要在成功删除该结点的同时，依旧使这棵树为二叉排序树。

假设要删除的为结点 p，则对于二叉排序树来说，需要根据结点 p 所在不同的位置作不同的操作，有以下 3 种可能：

1、结点 p 为叶子结点，此时只需要删除该结点，并修改其父结点的指针即可；
2、结点 p 只有左子树或者只有右子树，此时只需要将其左子树或者右子树直接变为结点 p 父结点的左子树即可；
3、结点 p 左右子树都有，此时有两种处理方式：	
- 令结点 p 的左子树为其双亲结点的左子树；结点 p 的右子树为其自身直接前驱结点的右子树。
- 用结点 p 的直接前驱（或直接后继）来代替结点 p，同时在二叉排序树中对其直接前驱（或直接后继）做删除操作。



使用二叉排序树在查找表中做查找操作的时间复杂度同建立的二叉树本身的结构有关。即使查找表中各数据元素完全相同，但是不同的排列顺序，构建出的二叉排序树大不相同。

例如：查找表 {45，24，53，12，37，93} 和表 {12，24，37，45，53，93} 各自构建的二叉排序树图下图所示：

![不同构造的二叉排序树](http://data.biancheng.net/uploads/allimg/171016/2-1G0161532523G.png)

使用二叉排序树实现动态查找操作的过程，实际上就是从二叉排序树的根结点到查找元素结点的过程，所以时间复杂度同被查找元素所在的树的深度（层次数）有关。

为了弥补二叉排序树构造时产生如图中右侧所示的影响算法效率的因素，需要对二叉排序树做“平衡化”处理，使其成为一棵 **平衡二叉树** 。





#### 平衡二叉树（AVL树） 

平衡二叉树，又称为 AVL 树。实际上就是遵循以下两个特点的二叉树：

- 每棵子树中的左子树和右子树的深度差不能超过 1；
- 二叉树中每棵子树都要求是平衡二叉树；

其实就是在二叉树的基础上，若树中每棵子树都满足其左子树和右子树的深度差都不超过 1，则这棵二叉树就是平衡二叉树。

![平衡与不平衡的二叉树及结点的平衡因子](http://data.biancheng.net/uploads/allimg/171024/2-1G02409242TY.png)

**平衡因子**：每个结点都有其各自的平衡因子，表示的就是其左子树深度同右子树深度的差。平衡二叉树中各结点平衡因子的取值只可能是：0、1 和 -1。

如图所示，其中 （a） 的两棵二叉树中由于各个结点的平衡因子数的绝对值都不超过 1，所以 （a） 中两棵二叉树都是平衡二叉树；而 （b） 的两棵二叉树中有结点的平衡因子数的绝对值超过 1，所以都不是平衡二叉树。



**二叉排序树转化为平衡二叉树**

为了排除动态查找表中不同的数据排列方式对算法性能的影响，需要考虑在不会破坏二叉排序树本身结构的前提下，将二叉排序树转化为平衡二叉树。

例如，使用上一节的算法在对查找表 `{13，24，37，90，53}` 构建二叉排序树时，当插入 13 和 24 时，二叉排序树此时还是平衡二叉树。

![平衡二叉树](http://data.biancheng.net/uploads/allimg/171024/2-1G024092HG93.png)

当继续插入 37 时，生成的二叉排序树如下图（a），平衡二叉树的结构被破坏，此时只需要对二叉排序树做“旋转”操作（如下图（b）），即整棵树以结点 24 为根结点，二叉排序树的结构没有破坏，同时将该树转化为了平衡二叉树：

![二叉排序树变为平衡二叉树的过程](http://data.biancheng.net/uploads/allimg/171024/2-1G024092K3431.png)

> 当二叉排序树的平衡性被打破时，就如同扁担的两头出现了一头重一头轻的现象，如上图（a）所示，此时只需要改变扁担的支撑点（树的树根），就能使其重新归为平衡。实际上图中的 （b） 是对（a） 的二叉树做了一个向左逆时针旋转的操作。

继续插入 90 和 53 后，二叉排序树如下图（a）所示，导致二叉树中结点 24 和 37 的平衡因子的绝对值大于 1 ，整棵树的平衡被打破。此时，需要做两步操作：
1. 如下图（b） 所示，将结点 53 和 90 整体向右顺时针旋转，使本该以 90 为根结点的子树改为以结点 53 为根结点；
2. 如下图（c） 所示，将以结点 37 为根结点的子树向左逆时针旋转，使本该以 37 为根结点的子树，改为以结点 53 为根结点；
3. 做完以上操作，即完成了由不平衡的二叉排序树转变为平衡二叉树。

![二叉排序树转化为平衡二叉树](http://data.biancheng.net/uploads/allimg/171024/2-1G024092Z6354.png)



当平衡二叉树由于新增数据元素导致整棵树的平衡遭到破坏时，就需要根据实际情况做出适当的调整，假设距离插入结点最近的 **不平衡因子** 为 a。则调整的规律可归纳为以下 4 种情况：

- **单向右旋平衡处理**：若由于结点 a 的左子树为根结点的左子树上插入结点，导致结点 a 的平衡因子由 1 增至 2，致使以 a 为根结点的子树失去平衡，则只需进行一次向右的顺时针旋转，如下图这种情况：

![单向右旋](http://data.biancheng.net/uploads/allimg/171024/2-1G024093156123.png)



- **单向左旋平衡处理**：如果由于结点 a 的右子树为根结点的右子树上插入结点，导致结点 a 的平衡因子由 -1变为 -2，则以 a 为根结点的子树需要进行一次向左的逆时针旋转，如下图这种情况：

![单向左旋](http://data.biancheng.net/uploads/allimg/171024/2-1G024093224129.png)



- **双向旋转（先左后右）平衡处理**：如果由于结点 a 的左子树为根结点的右子树上插入结点，导致结点 a 平衡因子由 1 增至 2，致使以 a 为根结点的子树失去平衡，则需要进行两次旋转操作，即先由作为根节点的左子树进行左旋，然后根节点进行右旋，如下图这种情况：

![双向旋转（先左后右）](http://data.biancheng.net/uploads/allimg/171024/2-1G02409324VJ.png)

注意：上图中插入结点也可以为结点 C 的右孩子，则（b）中插入结点的位置还是结点 C 右孩子，（c）中插入结点的位置为结点 A 的左孩子。



- **双向旋转（先右后左）平衡处理**：如果由于结点 a 的右子树为根结点的左子树上插入结点，导致结点 a 平衡因子由 -1 变为 -2，致使以 a 为根结点的子树失去平衡，则需要进行两次旋转（先右旋后左旋）操作，如下图这种情况：

![双向旋转（先右后左）](http://data.biancheng.net/uploads/allimg/171024/2-1G0240933303b.png)

注意：上图中插入结点也可以为结点 C 的右孩子，则（b）中插入结点的位置改为结点 B 的左孩子，（c）中插入结点的位置为结点 B 的左孩子。

在对查找表 `{13，24，37，90，53}` 构建平衡二叉树时，由于符合第 4 条的规律，所以进行先右旋后左旋的处理，最终由不平衡的二叉排序树转变为平衡二叉树。

使用平衡二叉树进行查找操作的时间复杂度为  `O(logn)`。在学习本节内容时，紧贴本节图示比较容易理解。





#### 红黑树

红黑树算法和应用，更高级的二叉查找树

**红黑树**（R-B TREE，全称：Red-Black Tree），本身是一棵二叉查找树，在其基础上附加了两个要求：
1. 树中的每个结点增加了一个用于存储颜色的标志域；
2. 树中没有一条路径比其他任何路径长出两倍，整棵树要接近于“平衡”的状态。

**路径** ：指的是从任何一个结点开始，一直到其子孙的叶子结点的长度。

**接近于平衡** ：红黑树并不是平衡二叉树，只是由于对各路径的长度之差有限制，所以近似于平衡的状态。



红黑树对于结点的颜色设置不是任意的，需满足以下性质的二叉查找树才是红黑树：

- 树中的每个结点颜色是排他单一的，非红即黑；
- 根结点的颜色是黑的；
- 所有为 nil 的叶子结点的颜色是黑的；（注意：叶子结点说的只是为空（nil 或NULL）的叶子结点！）
- 如果此结点是红的，那么它的两个孩子结点全部都是黑的；
- 对于每个结点，从该结点到到该结点的所有子孙结点的所有路径上包含有相同数目的黑结点；

![红黑树](http://image109.360doc.com/DownloadImg/2018/09/0419/143252963_21_20180904075907629)

注意：图中每个结点附带一个整形数值，表示的是此结点的 **黑高度** （从该结点到其子孙结点中包含的黑结点数，用bh(x)表示（x 表示此结点）），nil 的黑高度为0，颜色为黑色（在编程时为节省空间，所有的nil 共用一个存储空间）。在计算黑高度时，也看做是一个黑结点。


红黑树中每个结点都有各自的黑高度，整棵树也有自己的黑高度，即为根结点的黑高度，例如图中的红黑树的黑高度为3。

对于一棵具有n 个结点的红黑树，树的高度至多为：`2lg(n+1)` 。

由此可推出红黑树进行查找操作时的时间复杂度为 `O(lgn)` ，因为对于高度为h 的二叉查找树的运行时间为O(h)，而包含有n 个结点的红黑树本身就是最高为 lgn（简化之后）的查找树（h=lgn），所以红黑树的时间复杂度为 `O(lgn)`。

红黑树本身作为一棵二叉查找树，所以其任务就是用于动态表中数据的插入和删除的操作。在进行该操作时，避免不了会破坏红黑树的结构，此时就需要进行适当的调整，使其重新成为一棵红黑树，可以从两个方面着手对树进行调整：

- 调整树中某些结点的指针结构；
- 调整树中某些结点的颜色；



**红黑树的旋转**

当使用红黑树进行插入或者删除结点的操作时，可能会破坏红黑树的5 条性质，从而变成了一棵普通树，此时就可以通过对树中的某些子树进行旋转，从而使整棵树重新变为一棵红黑树。

**旋转操作 分为 左旋 和 右旋** ，同二叉排序树转平衡二叉树的旋转原理完全相同。

**左旋** ：左旋时y 结点变为该部分子树的根结点，同时x 结点（连同其左子树a）移动至y 结点的左孩子。若y结点有左孩子b，由于x 结点需占用其位置，所以调整至x 结点的右孩子处。

**右旋**：同左旋是同样的道理，x 结点变为根结点，同时y 结点连同其右子树c 作为x 结点的右子树，原x 结点的右子树b 变为y 结点的左子树。



**红黑树中插入新结点**

当创建一个红黑树或者向已有红黑树中插入新的数据时，只需要按部就班地执行以下3 步：

- 由于红黑树本身是一棵二叉查找树，所以在插入新的结点时，完全按照二叉查找树插入结点的方法，找到新结点插入的位置；
- 将新插入的结点初始化，颜色设置为红色后插入到指定位置；（将新结点初始化为红色插入后，不会破坏红黑树第5 条的性质）
- 由于插入新的结点，可能会破坏红黑树第4 条的性质（若其父结点颜色为红色，就破坏了红黑树的性质），此时需要调整二叉查找树，想办法通过旋转以及修改树中结点的颜色，使其重新成为红黑树！

插入结点的第1 步和第2 步都非常简单，关键在于最后一步对树的调整！在红黑树中插入结点时，根据插入位置的不同可分为以下3 种情况：
1. 插入位置为整棵树的树根。处理办法：只需要将插入结点的颜色改为黑色即可。
2. 插入位置的双亲结点的颜色为黑色。处理方法：此种情况不需要做任何工作，新插入的颜色为红色的结点不会破坏红黑树的性质。
3. 插入位置的双亲结点的颜色为红色。处理方法：由于插入结点颜色为红色，其双亲结点也为红色，破坏了红黑树第4 条性质，此时需要结合其祖父结点和祖父结点的另一个孩子结点（父结点的兄弟结点，此处称为“叔叔结点”）的状态进行讨论：
- 当前结点的父节点是红色，且“叔叔结点”也是红色：破坏了红黑树的第4 条性质，解决方案为：将父结点颜色改为黑色；将叔叔结点颜色改为黑色；将祖父结点颜色改为红色；下一步将祖父结点认做当前结点，继续判断，直到符合5条性质为止。
- 当前结点的父结点颜色为红色，叔叔结点颜色为黑色，且当前结点是父结点的右孩子。解决方案：将父结点作为当前结点做左旋操作，然后按照第三种情况进行操作。
- 当前结点的父结点颜色为红色，叔叔结点颜色为黑色，且当前结点是父结点的左孩子。解决方案：将父结点颜色改为黑色，祖父结点颜色改为红色，从祖父结点处进行右旋处理。



**红黑树中删除结点**

在红黑树中删除结点，思路更简单，只需要完成2 步操作：
1. 将红黑树按照二叉查找树删除结点的方法删除指定结点；
2. 重新调整删除结点后的树，使之重新成为红黑树；（还是通过旋转和重新着色的方式进行调整）

在二叉查找树删除结点时，分为3 种情况：

- 若该删除结点本身是叶子结点，则可以直接删除；
- 若只有一个孩子结点（左孩子或者右孩子），则直接让其孩子结点顶替该删除结点；
- 若有两个孩子结点，则找到该结点的右子树中值最小的叶子结点来顶替该结点，然后删除这个值最小的叶子结点。

以上三种情况最终都需要删除某个结点，此时需要判断删除该结点是否会破坏红黑树的性质。判断的依据是：
1. 如果删除结点的颜色为红色，则不会破坏；
2. 如果删除结点的颜色为黑色，则肯定会破坏红黑树的第5 条性质，此时就需要对树进行调整，调整方案分4 种情况讨论：

- 删除结点的兄弟结点颜色是红色，调整措施为：将兄弟结点颜色改为黑色，父亲结点改为红色，以父亲结点来进行左旋操作，同时更新删除结点的兄弟结点（左旋后兄弟结点发生了变化）
- 删除结点的兄弟结点及其孩子全部都是黑色的，调整措施为：将删除结点的兄弟结点设为红色，同时设置删除结点的父结点标记为新的结点，继续判断；
- 删除结点的兄弟结点是黑色，其左孩子是红色，右孩子是黑色。调整措施为：将兄弟结点设为红色，兄弟结点的左孩子结点设为黑色，以兄弟结点为准进行右旋操作，最终更新删除结点的兄弟结点；
- 删除结点的兄弟结点是黑色，其右孩子是红色（左孩子不管是什么颜色），调整措施为：将删除结点的父结点的颜色赋值给其兄弟结点，然后再设置父结点颜色为黑色，兄弟结点的右孩子结点为黑色，根据其父结点做左旋操作，最后设置替换删除结点的结点为根结点；



**总结**

红黑树，虽隶属于二叉查找树，但是二叉查找树的时间复杂度会受到其树深度的影响，而红黑树可以保证在最坏情况下的时间复杂度仍为`O(lgn)`。当数据量多到一定程度时，使用红黑树比二叉查找树的效率要高。

同平衡二叉树相比较，红黑树没有像平衡二叉树对平衡性要求的那么苛刻，虽然两者的时间复杂度相同，但是红黑树在实际测算中的速度要更胜一筹！

平衡二叉树的时间复杂度是`O(logn)`，红黑树的时间复杂度为`O(lgn)`，两者都表示的都是时间复杂度为对数关系（lg 函数为底是10 的对数，用于表示时间复杂度时可以忽略）。





#### B-树及其基本操作

`B-树`，有时又写为 `B_树`（其中的 `-` 或者 `_` 只是连字符，并不读作“B 减树”），一颗m 阶的B-树，如果本身不是空树，则必须满足以下特性：

- 树中每个结点至多有m 棵子树；
- 若根结点不是叶子结点，则至少有两棵子树；
- 除根之外的所有非终端结点至少有 `⌈m/2⌉` 棵子树；
- 所有的非终端结点中包含下列信息数据：（n，A<sub>0</sub>，K<sub>1</sub>，A<sub>1</sub>，K<sub>2</sub>，A<sub>2</sub>，…，K<sub>n</sub>，A<sub>n</sub>）；

> n 表示结点中包含的关键字的个数，取值范围是：`⌈ m/2⌉ -1≤ n ≤m-1`。 K<sub>i</sub> （i 从1 到n）为关键字，且K<sub>i</sub> < K<sub>i+1</sub> ；
> A<sub>i</sub> 代表指向子树根结点的指针，且指针A<sub>i-1</sub> 所指的子树中所有结点的关键字都小于K<sub>i</sub>，A<sub>n</sub> 所指子树中所有的结点的关键字都大于K<sub>n</sub>。

| 4 | A<sub>0</sub> | K<sub>1</sub> | A<sub>1</sub> | K<sub>2</sub> | A<sub>2</sub> | K<sub>3</sub> | A<sub>3</sub> | K<sub>4</sub> | A<sub>4</sub> |

如上图所示，是一个结点结构，当前结点中有4 个关键字，之间的关系为： K<sub>1</sub> < K<sub>2</sub> < K<sub>3</sub> < K<sub>4</sub> 。同时对于 A<sub>0</sub> 指针指向的子树中的所有关键字来说，其值都要比 K<sub>1</sub> 小；而 A<sub>1</sub> 指向的子树中的所有的关键字的值，都比 K<sub>1</sub> 大，但是都要比 K<sub>2</sub> 小。

- 所有的叶子结点都出现在同一层次，实际上这些结点都不存在，指向这些结点的指针都为NULL；

![B树](https://gss2.bdstatic.com/-fo3dSag_xI4khGkpoWK1HF6hhy/baike/crop%3D24%2C0%2C562%2C372%3Bc0%3Dbaike80%2C5%2C5%2C80%2C26/sign=0748d48373ec54e755a3405e840aaf7c/2cf5e0fe9925bc317a17582556df8db1ca1370c0.jpg)

在使用B-树进行查找操作时，例如上图百度来的图片中，在B-树中查找关键字37 的过程为：
1. 从整棵树的根结点开始，由于根结点只有一个关键字13，且13 < 37 ，所以如果37 存在于这棵树中，肯定位于A1 指针指向的右子树中；
2. 然后顺着指针找到存有关键字23,31 和43 的结点，由于31 < 37 < 43，所以如果37 存在，肯定位于A2 所指的子树中；
3. 然后找到存有31、37 和41 三个关键字的结点，最终找到37 ，查找操作结束；
4. 若查找到深度为3 的结点还没结束，则会进入叶子结点，但是由于叶子结点本身不存储任何信息，全部为NULL，所以查找失败。



**B-树中插入关键字(构建B-树)**

B-树也是从空树开始，通过不断地插入新的数据元素构建的。但是B-树构建的过程同前面章节的二叉排序树和平衡二叉树不同，B-树在插入新的数据元素时并不是每次都向树中插入新的结点。

因为对于m 阶的B-树来说，在定义中规定所有的非终端结点（终端结点即叶子结点，其关键字个数为0）中包含关键字的个数的范围是 `[⌈ m/2⌉ -1,m-1]`，所以在插入新的数据元素时，首先向最底层的某个非终端结点中添加，如果该结点中的关键字个数没有超过m-1，则直接插入成功，否则还需要继续对该结点进行处理。

**B-树中删除关键字**

在B-树中删除关键字时，首先前提是找到该关键字所在结点，在做删除操作的时候分为两种情况，一种情况是删除结点为B-树的非终端结点（不处在最后一层）；另一种情况是删除结点为B-树最后一层的非终端结点。

如果该结点为非终端结点且不处在最后一层，假设用Ki 表示，则只需要找到指针Ai 所指子树中最小的一个关键字代替Ki，同时将该最小的关键字删除即可。

如果该结点为最后一层的非终端结点，有下列3 种可能：

- 被删关键字所在结点中的关键字数目不小于 `⌈ m/2⌉` ，则只需从该结点删除该关键字Ki 以及相应的指针Ai 。
- 被删关键字所在结点中的关键字数目等于`⌈ m/2⌉ - 1`，而与该结点相邻的右兄弟结点（或者左兄弟）结点中的关键字数目大于`⌈ m/2⌉ - 1`，只需将该兄弟结点中的最小（或者最大）的关键字上移到双亲结点中，然后将双亲结点中小于（或者大于）且紧靠该上移关键字的关键字移动到被删关键字所在的结点中。
- 被删除关键字所在的结点如果和其相邻的兄弟结点中的关键字数目都正好等于`⌈ m/2⌉ - 1`，假设其有右兄弟结点，且其右兄弟结点是由双亲结点中的指针Ai 所指，则需要在删除该关键字的同时，将剩余的关键字和指针连同双亲结点中的Ki 一起合并到右兄弟结点中。

由于B-树具有分支多层数少的特点，使得它更多的是应用在数据库系统中。除了B-树，还有专门为文件系统而生的B+树。





#### B+树及其基本操作

B+树是应文件系统而生的一种B树的变型树。

一颗 m 阶的 B+ 树和 m 阶的 B- 树的差异在于：

- 有 n 棵子树的结点中含有 n 个关键字；在B-树中的每个结点关键字个数n 的取值范围为 ⌈ m/2⌉ -1 ≤ n ≤ m-1，而在 B+ 树中每个结点中关键字个数 n 的取值范围为：⌈ m/2⌉ ≤ n ≤ m。
- 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
- 所有的非叶子结点可以看成是索引部分，结点中仅含有其子树（根结点）中的最大（或最小）关键字。

B+树中含有两个头指针，一个指向整棵树的根结点，另一个指向关键字最小的叶子结点。同时所有的叶子结点依据其关键字的大小自小而大顺序链接，所有的叶子结点构成了一个sqt 指针为头指针的链表。

B+树可以进行两种查找运算：

- 一种是利用sqt 链表做顺序查找。
- 另一种是从树的根结点开始，进行类似于二分查找的查找方式。

在B+树中，所有非终端结点都相当于是终端结点的索引，而所有的关键字都存放在终端结点中，所有在从根结点出发做查找操作时，如果非终端结点上的关键字恰好等于给定值，此时并不算查找完成，而是要继续向下直到叶子结点。

B+树的查找操作，无论查找成功与否，每次查找操作都是走了一条从根结点到叶子结点的路径。



**B+树中插入关键字**

在B+树中插入关键字时，需要注意以下几点：

- 插入的操作全部都在叶子结点上进行，且不能破坏关键字自小而大的顺序；
- 由于B+树中各结点中存储的关键字的个数有明确的范围，做插入操作可能会出现结点中关键字个数超过阶数的情况，此时需要将该结点进行“分裂”；

B+树中做插入关键字的操作，有以下3 种情况：
1. 若被插入关键字所在的结点，其含有关键字数目小于阶数M，则直接插入结束；
2. 若被插入关键字所在的结点，其含有关键字数目等于阶数M，则需要将该结点分裂为两个结点，一个结点包含⌊ M/2⌋ ，另一个结点包含⌈ M/2⌉ 。同时，将⌈ M/2⌉ 的关键字上移至其双亲结点。假设其双亲结点中包含的关键字个数小于M，则插入操作完成。
3. 在第2 情况中，如果上移操作导致其双亲结点中关键字个数大于M，则应继续分裂其双亲结点。

> 注意：如果插入的关键字比当前结点中的最大值还大，破坏了B+树中从根结点到当前结点的所有索引值，此时需要及时修正后，再做其他操作。



**B+树中删除关键字**

在B+树中删除关键字时，有以下几种情况：

1. 找到存储有该关键字所在的结点时，由于该结点中关键字个数大于⌈ M/2⌉ ，做删除操作不会破坏B+树，则可以直接删除。
2. 当删除某结点中最大或者最小的关键字，就会涉及到更改其双亲结点一直到根结点中所有索引值的更改。
3. 当删除该关键字，导致当前结点中关键字个数小于⌈ M/2⌉ ，若其兄弟结点中含有多余的关键字，可以从兄弟结点中借关键字完成删除操作。
4. 第3 种情况中，如果其兄弟结点没有多余的关键字，则需要同其兄弟结点进行合并。
5. 当进行合并时，可能会产生因合并使其双亲结点破坏B+树的结构，需要依照以上规律处理其双亲结点。



**总结**

总之，在B+树中做删除关键字的操作，采取如下的步骤：
1. 删除该关键字，如果不破坏B+树本身的性质，直接完成操作；
2. 如果删除操作导致其该结点中最大（或最小）值改变，则应相应改动其父结点中的索引值；
3. 在删除关键字后，如果导致其结点中关键字个数不足，有两种方法：一种是向兄弟结点去借，另外一种是同兄弟结点合并。（注意这两种方式有时需要更改其父结点中的索引值。）

本节介绍了有关B+树的查找、插入和删除操作，由于其更多的是用于文件索引系统，所以没有介绍具体地代码实现，只需要了解实现过程即可。





#### 键树及其基本操作

键树，又称为数字查找树（根结点的子树个数>= 2），同以往所学习的树不同的是， **键树的结点中存储的不是某个关键字，而是只含有组成关键字的单个符号**。

如果关键字本身是字符串，则键树中的一个结点只包含有一个字符；如果关键字本身是数字，则键树中的一个结点只包含一个数位。每个关键字都是从键树的根结点到叶子结点中经过的所有结点中存储的组合。

![键树](https://pic002.cnblogs.com/images/2012/325852/2012111522213138.png)

> 注意：键树中叶子结点的特殊符号$ 为结束符，表示字符串的结束。使用键树表示查找表时，为了方便后期的查找和插入操作，约定键树是有序树（兄弟结点之间自左至右有序），同时约定结束符 $ 小于任何字符。



**键树的存储结构**

键树的存储结构有两种：
1. 一种是通过使用树的孩子兄弟表示法来表示键树，即 **双链树** ；
2. 另一种是以树的多重链表表示键树，即Trie树，又称 **字典树** 。



**双链树**

当使用孩子兄弟表示法表示键树时，树的结点构成分为3 部分：

- symbol 域：存储关键字的一个字符；
- first 域：存储指向孩子结点的指针；
- next 域：存储指向兄弟结点的指针；

> 注意：对于叶子结点来说，由于其没有孩子结点，在构建叶子结点时，将first 指针换成infoptr 指针，用于指向该关键字。当叶子结点（结束符‘$’ 所在的结点）中使用infoptr 域指向该自身的关键字时，此时的键树被称为双链树。

> 提示：每个关键字的叶子结点$ 的infoptr 指针指向的是各自的关键字，通过该指针就可以找到各自的关键字的首地址。

在使用孩子兄弟表示法表示的键树中做查找操作，从树的根结点出发，依次同被查找的关键字进行比对，如果比对成功，进行下一字符的比对；反之，如果比对失败，则跳转至该结点的兄弟结点中去继续比对，直至比对成功或者为找到该关键字。

**代码实现**

```c
#include <stdio.h>
typedef enum {LEFT, BRANCH} NodeKind; //定义结点的类型，是叶子结点还是其他类型的结点
typedef struct
{
    char a[20];//存储关键字的数组
    int num;//关键字长度
} KeysType;
//定时结点结构
typedef struct DLTNode
{
    char symbol;//结点中存储的数据
    struct DLTNode *next;//指向兄弟结点的指针
    NodeKind *kind;//结点类型
    union //其中两种指针类型每个结点二选一
    {
        struct DLTNode *first;//孩子结点
        struct DLTNode *infoptr;//叶子结点特有的指针
    };
} *DLTree;
//查找函数，如果查找成功，返回该关键字的首地址，反则返回NULL。T 为用孩子兄弟表示法表示的键树，K 为被查找的关键字。
DLTree SearchChar(DLTree T, KeysType k)
{
    int i = 0;
    DLTree p = T->first;//首先令指针P 指向根结点下的含有数据的孩子结点
    //如果p 指针存在，且关键字中比对的位数小于总位数时，就继续比对
    while (p && i < k.num)
    {
        //如果比对成功，开始下一位的比对
        if (k.a[i] == p->symbol)
        {
            i++;
            p = p->first;
        }
        //如果该位比对失败，则找该结点的兄弟结点继续比对
        else
        {
            p = p->next;
        }
    }
    //比对完成后，如果比对成功，最终p 指针会指向该关键字的叶子结点$，通过其自有的infoptr 指针找到该关键字。
    if ( i == k.num)
    {
        return p->infoptr;
    }
    else
    {
        return NULL;
    }
}
```



**Trie树(字典树)**

若以树的多重链表表示键树，则树中如同双链树一样，会含有两种结点：
1. 叶子结点：叶子结点中含有关键字域和指向该关键字的指针域；
2. 除叶子结点之外的结点（分支结点）：含有d 个指针域和一个整数域（记录该结点中指针域的个数）；

> d 表示每个结点中存储的关键字的所有可能情况，如果存储的关键字为数字，则d= 11（0—9，以及$），同理，如果存储的关键字为字母，则d=27（26 个字母加上结束符$）。

> 注意：在Trie 树中，如果从某个结点一直到叶子结点都只有一个孩子，这些结点可以用一个叶子结点来代替。

使用Trie 树进行查找时，从根结点出发，沿和对应关键字中的值相对应的指针逐层向下走，一直到叶子结点，如果全部对应相等，则查找成功；反之，则查找失败。

**代码实现**

```c
typedef enum {LEFT, BRANCH} NodeKind; //定义结点类型
typedef struct  //定义存储关键字的数组
{
    char a[20];
    int num;
} KeysType;
//定义结点结构
typedef struct TrieNode
{
    NodeKind kind;//结点类型
    union
    {
        struct
        {
            KeysType k;
            struct TrieNode *infoptr;
        } lf; //叶子结点
        struct
        {
            struct TrieNode *ptr[27];
            int num;
        } bh; //分支结点
    };
} *TrieTree;
//求字符a 在字母表中的位置
int ord(char a)
{
    int b = a - 'A' + 1;
    return b;
}

//查找函数
TrieTree SearchTrie(TrieTree T, KeysType K)
{
    int i = 0;
    TrieTree p = T;
    while (i < K.num)
    {
        if (p && p->kind == BRANCH && p->bh.ptr[ord(K.a[i])])
        {
            i++;
            p = p->bh.ptr[ord(K.a[i])];
        }
        else
        {
            break;
        }
    }
    if (p)
    {
        return p->lf.infoptr;
    }
    return p;
}
```

**总结**

使用Trie 树进行查找的过程实际上是走了一条从根结点到叶子结点的路径，所以 **使用Trie 进行的查找效率取决于该树的深度** 。

双链树和字典树是键树的两种表示方法，各有各的特点，具体使用哪种方式表示键树，需要根据实际情况而定。例如，若键树中结点的孩子结点较多，则使用字典树较双链树更为合适。





#### 哈希表（散列表）及哈希表处理冲突的方法

前面介绍了静态查找表以及动态查找表中的一些查找方法，其查找的过程都无法避免同查找表中的数据进行比较，查找算法的效率很大程度取决于同表中数据的查找次数。

而本节所介绍的哈希表可以通过关键字直接找到数据的存储位置，不需要进行任何的比较，其查找的效率相较于前面所介绍的查找算法是更高的。



**哈希表的构建**

在初中的数学课本中学习过函数的相关知识，给定一个 x，通过一个数学公式，只需要将 x 的值带入公式就可以求出一个新的值 y。

哈希表的建立同函数类似，把函数中的 x 用查找记录时使用的关键字来代替，然后将关键字的值带入一个精心设计的公式中，就可以求出一个值，用这个值来表示记录存储的 **哈希地址** 。

> 数据的哈希地址=f（关键字的值）

> **哈希地址** 只是表示在查找表中的存储位置，而不是实际的物理存储位置。f（）是一个函数，通过这个函数可以快速求出该关键字对应的的数据的哈希地址，称之为“哈希函数”。

**在构建哈希表时，最重要的是哈希函数的设计** 。 例如设计电话簿案例中的哈希函数为：每个名字的姓的首字母的 ASCII 值即为对应的电话号码的存储位置。这时会发现，张三和赵六两个关键字的姓的首字母都是 Z ，最终求出的电话号码的存储位置相同，这种现象称为冲突。在设计哈希函数时，要尽量地避免冲突现象的发生。

对于哈希表而言，冲突只能尽可能地少，无法完全避免。



**哈希函数的构造**

常用的哈希函数的构造方法有 6 种：直接定址法、数字分析法、平方取中法、折叠法、除留余数法和随机数法。

- 直接定址法
其哈希函数为一次函数，即以下两种形式：
`H（key）= key 或者 H（key）=a * key + b`
其中 H（key）表示关键字为 key 对应的哈希地址，a 和 b 都为常数。

- 数字分析法
如果关键字由多位字符或者数字组成，就可以考虑抽取其中的 2 位或者多位作为该关键字对应的哈希地址，在取法上尽量选择变化较多的位，避免冲突发生。

- 平方取中法
平方取中法是对关键字做平方操作，取中间得几位作为哈希地址。此方法也是比较常用的构造哈希函数的方法。

- 折叠法
折叠法是将关键字分割成位数相同的几部分（最后一部分的位数可以不同），然后取这几部分的叠加和（舍去进位）作为哈希地址。此方法适合关键字位数较多的情况。

- 除留余数法
若已知整个哈希表的最大长度 m，可以取一个不大于 m 的数 p，然后对该关键字 key 做取余运算，即：`H（key）= key % p` 。
在此方法中，对于 p 的取值非常重要，由经验得知 p 可以为不大于 m 的质数或者不包含小于 20 的质因数的合数。

- 随机数法
是取关键字的一个随机函数值作为它的哈希地址，即： `H（key）=random（key）` ，此方法适用于关键字长度不等的情况。
注意：这里的随机函数其实是伪随机函数，随机函数是即使每次给定的 key 相同，但是 H（key）都是不同；而伪随机函数正好相反，每个 key 都对应的是固定的 H（key）。



如此多的构建哈希函数的方法，在选择的时候，需要根据实际的查找表的情况采取适当的方法。通常考虑的因素有以下几方面：

- 关键字的长度。如果长度不等，就选用随机数法。如果关键字位数较多，就选用折叠法或者数字分析法；反之如果位数较短，可以考虑平方取中法；
- 哈希表的大小。如果大小已知，可以选用除留余数法；
- 关键字的分布情况；
- 查找表的查找频率；
- 计算哈希函数所需的时间（包括硬件指令的因素）



**处理冲突的方法**

对于哈希表的建立，需要选取合适的哈希函数，但是对于无法避免的冲突，需要采取适当的措施去处理。

通常用的处理冲突的方法有以下几种：

- 开放定址法 
`H（key）=（H（key）+ d）MOD m（其中 m 为哈希表的表长，d 为一个增量）`
当得出的哈希地址产生冲突时，选取以下 3 种方法中的一种获取 d 的值，然后继续计算，直到计算出的哈希地址不在冲突为止，这 3 种方法为：
1. 线性探测法：d=1，2，3，…，m-1
2. 二次探测法：d=12，-12，22，-22，32，…
3. 伪随机数探测法：d=伪随机数

> 在线性探测法中，当遇到冲突时，从发生冲突位置起，每次 +1，向右探测，直到有空闲的位置为止；二次探测法中，从发生冲突的位置起，按照 +12，-12，+22，…如此探测，直到有空闲的位置；伪随机探测，每次加上一个随机数，直到探测到空闲位置结束。

- 再哈希法
当通过哈希函数求得的哈希地址同其他关键字产生冲突时，使用另一个哈希函数计算，直到冲突不再发生。

- 链地址法
将所有产生冲突的关键字所对应的数据全部存储在同一个线性链表中。

- 建立一个公共溢出区
建立两张表，一张为基本表，另一张为溢出表。基本表存储没有发生冲突的数据，当关键字由哈希函数生成的哈希地址产生冲突时，就将数据填入溢出表。





#### 哈希表查找算法

在哈希表中进行查找的操作同哈希表的构建过程类似，其具体实现思路为：

对于给定的关键字K，将其带入哈希函数中，求得与该关键字对应的数据的哈希地址，如果该地址中没有数据，则证明该查找表中没有存储该数据，查找失败；如果哈希地址中有数据，就需要做进一步的证明（排除冲突的影响），找到该数据对应的关键字同K 进行比对，如果相等，则查找成功；反之，如果不相等，说明在构造哈希表时发生了冲突，需要根据构造表时设定的处理冲突的方法找到下一个地址，同地址中的数据进行比对，直至遇到地址中数据为NULL（说明查找失败），或者比对成功。

> 回顾：哈希表在构造过程中，处理冲突的方法有：开放定址法、再哈希法、链地址法、建立公共溢出区法。



**查找算法的效率分析**

在构造哈希表的过程中，由于冲突的产生，使得哈希表的查找算法仍然会涉及到比较的过程，因此对于哈希表的查找效率仍需以平均查找长度来衡量。

在哈希表的查找过程中需和给定值进行比较的关键字的个数取决于以下3 个因素：

- **哈希函数**   哈希函数的“好坏”取决于影响出现冲突的频繁程度。但是一般情况下，哈希函数相比于后两种的影响，可以忽略不计。
- **处理冲突的方式**   对于同一组关键字，设定相同的哈希函数，使用不同的处理冲突的方式得到的哈希表是不同的，表的平均查找长度也不同。
- **哈希表的装填因子**   在一般情况下，当处理冲突的方式相同的情况下，其平均查找长度取决于哈希表的装满程度：装的越满，插入数据时越有可能发生冲突；反之则越小。

*装填因子 = 哈希表中数据的个数 / 哈希表的长度* ，用字符 α (读 alpha ) 表示。装填因子越小，表示哈希表中空闲的位置就越多。

经过计算，在假设查找表中的所有数据的查找概率相等的情况下，对于表长为m，数据个数为n 的哈希表：

- 其查找成功的平均查找长度约为：-1/α * ln⁡(1-α)
- 其查找不成功的平均查找长度约为：1/(1-α)

通过公式可以看到，哈希表的查找效率只同装填因子有关，而同哈希表中的数据的个数无关，所以在选用哈希表做查找操作时，选择一个合适的装填因子是非常有必要的。





### 排序算法

#### 插入排序

插入排序算法是所有排序方法中最简单的一种算法，其主要的实现思想是将数据按照一定的顺序一个一个的插入到有序的表中，最终得到的序列就是已经排序好的数据。

很多人所说的插入排序，实际上指的就是 **直接插入排序** 算法， 插入排序算法还包括 **折半插入排序** 、**2-路插入排序** ，**表插入排序** 和 **希尔排序** 等，后序文章都会一一讲到。

直接插入排序是插入排序算法中的一种，采用的方法是：在添加新的记录时，使用顺序查找的方式找到其要插入的位置，然后将新记录插入。



例如采用直接插入排序算法将无序表 `{3,1,7,5,2,4,9,6}` 进行升序排序的过程为：

- 首先考虑记录 3 ，由于插入排序刚开始，有序表中没有任何记录，所以 3 可以直接添加到有序表中 {3}
- 向有序表中插入记录 1 时，同有序表中记录 3 进行比较，1<3，所以插入到记录 3 的左侧 {1,3}
- 向有序表插入记录 7 时，同有序表中记录 3 进行比较，3<7，所以插入到记录 3 的右侧 {1,3,7}
- 向有序表中插入记录 5 时，同有序表中记录 7 进行比较，5<7，同时 5>3，所以插入到 3 和 7 中间 {1,3,5,7}
- 向有序表插入记录 2 时，同有序表中记录 7进行比较，2<7，再同 5，3，1分别进行比较，最终确定 2 位于 1 和 3 中间 {1,2,3,5,7}
- 照此规律，依次将无序表中的记录 4，9 和 6插入到有序表中 {1,2,3,4,5,6,7,9}

直接插入排序算法本身比较简洁，容易实现，该算法的时间复杂度为 `O(n2)` 。





#### 折半插入排序

之前介绍了 **直接插入排序算法** 的理论实现和具体的代码实现，如果你善于思考就会发现该算法在查找插入位置时，采用的是顺序查找的方式，而在查找表中数据本身有序的前提下，可以使用 **折半查找** 来代替 **顺序查找** ，这种排序的算法就是 **折半插入排序算法** 。

折半插入排序算法相比较于直接插入排序算法，只是减少了关键字间的比较次数，而记录的移动次数没有进行优化，所以该算法的时间复杂度仍是 `O(n2)`。

```c
#include <stdio.h>

void BInsertSort(int arr[], int n)
{
    int low = 0, high = 0, mid;
    int temp = 0;
    for (int i = 1; i < n; i++)
    {
        low = 0;
        high = i - 1;
        temp = arr[i];

        //采用折半查找法判断插入位置，最终变量 low 表示插入位置
        while (low <= high)
        {
            mid = (low + high) / 2; // 取上
            // 中位 > 顺序位，则取低位，反之取高位
            if (arr[mid] > temp)
            {
                high = mid - 1;
            }
            else
            {
                low = mid + 1;
            }
        }

        //有序表中插入位置后的元素统一后移
        for (int j = i; j > low; j--)
        {
            arr[j] = arr[j - 1];
        }
        arr[low] = temp; //插入元素

        // 打印排序后的数组
        printf("%d: ", i);
        for(int k = 0; k < n; k++)
        {
            printf("%d ", arr[k]);
        }
        printf("\n");
    }

}


int main(int argc, char const *argv[])
{
    int arr[8] = {3, 1, 7, 5, 2, 4, 9, 6};
    BInsertSort(arr, 8);
    getchar();
    return 0;
}


```





#### 2-路插入排序算法

2-路插入排序算法是在折半插入排序的基础上对其进行改进，减少其在排序过程中移动记录的次数从而提高效率。

具体实现思路为：另外设置一个同存储记录的数组大小相同的数组 d，将无序表中第一个记录添加进 d[0] 的位置上，然后从无序表中第二个记录开始，同 d[0] 作比较：如果该值比 d[0] 大，则添加到其右侧；反之添加到其左侧。

在这里的数组 d 可以理解成一个环状数组。

使用 2-路插入排序算法对无序表 `{3,1,7,5,2,4,9,6}` 排序的过程如下：

- 将记录 3 添加到数组 d 中: d[0]
- 然后将 1 插入到数组 d 中: d[7]
- 将记录 7 插入到数组 d 中: d[1]
- 将记录 5 插入到数组 d 中，由于其比 7小，但是比 3 大，所以需要移动 7 的位置 d[2]，然后将 5 插入: d[1]
- 将记录 2 插入到数组 d 中，由于比 1大，比 3 小，所以需要移动 3、5、7 的位置 d[1]、d[2]、d[3] ，然后将 2 插入: d[0]
- 将记录 4 插入到数组 d 中: d[2], 需要移动 5 和 7 的位置: d[3]、 d[4]
- 将记录 9 插入到数组 d 中: d[5]
- 将记录 6 插入到数组 d 中: d[4], 需要移动 7 和 9 的位置: d[5]、 d[6]

最终存储在原数组时，从 d[7] 开始依次存储。

2-路插入排序相比于折半插入排序，只是减少了移动记录的次数，没有根本上避免，所以其时间复杂度仍为 `O(n2)`。



```c
#include <stdio.h>
#include <stdlib.h>

void insert(int arr[], int temp[], int n)
{
    int first, final, k;
    first = 0; // 记录temp数组中最小值位置
    final = 0; // 记录temp数组中最大值位置
    temp[0] = arr[0];

    for (int i = 1; i < n; i ++)
    {
        // 待插入元素比最小的元素小
        if (arr[i] < temp[first])
        {
        	// 最小值的位置更新为数组末位, 如首次进入 7mod8=7
            first = (first - 1 + n) % n;
            // 待插入元素变为最小元素
            temp[first] = arr[i];
        }
        // 待插入元素比最大元素大
        else if (arr[i] > temp[final])
        {
        	// 最大值的位置更新为数组下一位，如首次进入 9mod8=1
            final = (final + 1 + n) % n;
            // 待插入元素变为最大元素
            temp[final] = arr[i];
        }
        // 插入元素比最小大，比最大小
        else
        {
        	// 最大值的位置更新到下一位
            k = (final + 1 + n) % n;
            //当插入值比当前值小时，需要移动当前值的位置
            while (temp[((k - 1) + n) % n] > arr[i])
            {
                temp[(k + n) % n] = temp[(k - 1 + n) % n];
                k = (k - 1 + n) % n;
            }
            //插入该值
            temp[(k + n) % n] = arr[i];
            //因为最大值的位置改变，所以需要实时更新final的位置
            final = (final + 1 + n) % n;
        }
    }
    // 将排序记录复制到原来的顺序表里
    for (k = 0; k < n; k ++)
    {
        arr[k] = temp[(first + k) % n];
    }
}


int main(int argc, char const *argv[])
{
    int arr[8] = {3, 1, 7, 5, 2, 4, 9, 6};
    int temp[8];
    for (int i = 0; i < 8; i++)
    {
        printf("%d ", arr[i]);
    }
    printf("\n");
    insert(arr, temp, 8);
    for (int i = 0; i < 8; i++)
    {
        printf("%d ", arr[i]);
    }
    getchar();
    return 0;
}
```





#### 表插入排序算法

直接插入排序、折半插入排序、2-路插入排序，其基本结构都采用数组的形式进行存储，因而无法避免排序过程中产生的数据移动的问题。如果想要从根本上解决只能改变数据的存储结构，改用链表存储。

**表插入排序，就是使用链表的存储结构对数据进行插入排序** 。

在对记录按照关键字进行排序的过程中，不需要移动记录的存储位置，只需要更改结点间指针的指向即可。



链表的存储结构：

```c
#define SIZE 100
typedef struct {
    int rc;//记录项
    int next;//指针项，由于在数组中，所以只需要记录下一个结点所在数组位置的下标即可。
}SLNode;
typedef struct {
    SLNode r[SIZE];//存储记录的链表
    int length;//记录当前链表长度
}SLinkListType;
```

在使用数组结构表示的链表中，设定数组下标为 0 的结点作为链表的表头结点，并令其关键字取最大整数。则表插入排序的具体实现过程是：

首先将链表中数组下标为 1 的结点和表头结点构成一个循环链表，然后将后序的所有结点按照其存储的关键字的大小，依次插入到循环链表中。

例如，将无序表 `{49，38，76，13，27}` 用表插入排序的方式进行排序，其过程为：

- 首先使存储 49 的结点与表头结点构成一个初始的循环链表，完成对链表的初始化

  ![1](http://data.biancheng.net/uploads/allimg/171031/2-1G0311053559D.png)

- 然后将以 38 为关键字的记录插入到循环链表中（只需要更改其链表的 next 指针即可）

  ![2](http://data.biancheng.net/uploads/allimg/171031/2-1G031105424251.png)

- 再将以 76 为关键字的结点插入到循环链表中，插入后的链表为:

  ![3](http://data.biancheng.net/uploads/allimg/171031/2-1G03110543U10.png)

- 再将以 13 为关键字的结点插入到循环链表中，插入后的链表为：

  ![4](http://data.biancheng.net/uploads/allimg/171031/2-1G031105450D4.png)

- 最后将以 27 为关键字的结点插入到循环链表中，插入后的链表为：

  ![5](http://data.biancheng.net/uploads/allimg/171031/2-1G031105501R0.png)

- 最终形成的循环链表为：

  ![6](http://data.biancheng.net/uploads/allimg/171031/2-1G0311055305c.png)



从表插入排序的实现过程上分析，与直接插入排序相比只是避免了移动记录的过程（修改各记录结点中的指针域即可），而插入过程中同其它关键字的比较次数并没有改变，所以表插入排序算法的时间复杂度仍是 `O(n2)` 。



**对链表进行再加工**

在表插入排序算法求得的有序表是用链表表示的，也就注定其只能进行顺序查找。而如果想用折半查找的算法，就需要对链表进行再加工，即对链表中的记录进行重新排列，具体做法为： **遍历链表，将链表中第 i 个结点移动至数组的第 i 个下标位置中** 。

实际上就是单纯的对数据进行排序，next指针就失去了意义。



```c
#include <stdio.h>
#include <stdlib.h>
#define SIZE 6


typedef struct
{
    int rc;//记录项
    int next;//指针项，由于在数组中，所以只需要记录下一个结点所在数组位置的下标即可。
} SLNode;
typedef struct
{
    SLNode r[SIZE];//存储记录的链表
    int length;//记录当前链表长度
} SLinkListType;
//重新排列函数
void Arrange(SLinkListType *SL)
{
    //令 p 指向当前要排列的记录
    int p = SL->r[0].next;
    for (int i = 1; i < SL->length; i++)
    {
        //如果条件成立，证明原来的数据已经移动，需要通过不断找 next 域，找到其真正的位置
        while (p < i)
        {
            p = SL->r[p].next;
        }
        //找到之后，令 q 指针指向其链表的下一个记录所在的位置
        int q = SL->r[p].next;
        //条件成立，证明需要同下标为 i 的记录进行位置交换
        if (p != i)
        {
            SLNode t;
            t = SL->r[p];
            SL->r[p] = SL->r[i];
            SL->r[i] = t;
            //交换完成后，该变 next 的值，便于后期遍历
            SL->r[i].next = p;
        }
        //最后令 p 指向下一条记录
        p = q;
    }
}

int main(int argc, const char *argv[])
{

    SLinkListType *SL = (SLinkListType *)malloc(sizeof(SLinkListType));
    SL->length = 6;
    SL->r[0].rc = 0;
    SL->r[0].next = 4;

    SL->r[1].rc = 49;
    SL->r[1].next = 3;

    SL->r[2].rc = 38;
    SL->r[2].next = 1;

    SL->r[3].rc = 76;
    SL->r[3].next = 0;

    SL->r[4].rc = 13;
    SL->r[4].next = 5;

    SL->r[5].rc = 27;
    SL->r[5].next = 2;

    printf("before:\n");
    for (int i = 1; i < 6; i++)
    {
        printf("%d ", SL->r[i].rc);
    }
    printf("\n");

    Arrange(SL);

    printf("after:\n");
    for (int i = 1; i < 6; i++)
    {
        printf("%d ", SL->r[i].rc);
    }
    getchar();
    return 0;
}
```





#### 希尔排序算法

希尔排序，又称“缩小增量排序”，也是插入排序的一种，但是同前面几种排序算法比较来看，希尔排序在时间效率上有很大的改进。

在使用直接插入排序算法时，如果表中的记录只有个别的是无序的，多数保持有序，这种情况下算法的效率也会比较高；除此之外，如果需要排序的记录总量很少，该算法的效率同样会很高。希尔排序就是从这两点出发对算法进行改进得到的排序算法。

希尔排序的具体实现思路是： *先将整个记录表分割成若干部分，分别进行直接插入排序，然后再对整个记录表进行一次直接插入排序* 。



例如无序表 `{49，38，65，97，76，13，27，49，55，4}` 进行希尔排序的过程为：

- 首先对 `{49，13}` ， `{38，27}` ， `{65，49}` ， `{97，55}` ， `{76，4}`  分别进行直接插入排序（如果需要调换位置也只是互换存储位置）
- 通过一次排序，无序表中的记录已基本有序，此时还可以再进行一次分割
- 经过两次分割，无序表中已基本有序，此时对整张表进行一次直接插入排序（只需要做少量的比较和插入操作即可）

希尔排序的过程中，对于分割的每个子表，其各自包含的记录在原表中并不是相互挨着的，而是相互之间相隔着某个固定的常数。

通过此种方式，对于关键字的值较小的记录，其前移的过程不是一步一步的，而是跳跃性的前移，并且在最后一次对整表进行插入排序时减少了比较和排序的次数。

一般在记录的数量多的情况下，希尔排序的排序效率较直接插入排序高。

提示：经过大量的研究表明，所选取的增量值最好是没有除1 之外的公因子，同时整个增量数组中最后一个增量值必须等于1 ，因为最后必须对整张表做一次直接插入排序算法。





#### 冒泡排序

起泡排序，别名“冒泡排序”，该算法的核心思想是将无序表中的所有记录，通过两两比较关键字，得出升序序列或者降序序列。

通过一趟趟的比较，一个个的“最大值”被找到并移动到相应位置，直到检测到表中数据已经有序，或者比较次数等同于表中含有记录的个数，排序结束，这就是起泡排序。

使用起泡排序算法，其时间复杂度同实际表中数据的无序程度有关。若表中记录本身为正序存放，则整个排序过程只需进行 n-1（n 为表中记录的个数）次比较，且不需要移动记录；若表中记录为逆序存放（最坏的情况），则需要 n-1趟排序，进行 n(n-1)/2 次比较和数据的移动。所以该算法的时间复杂度为 `O(n2)`。

```c
#include <stdio.h>


void bubleSort(int arr[], int n)
{
    int i, j, flag;
    int temp;
    for (i = n - 1; i > 0; --i)
    {
        flag = 0;
        for (j = 1; j <= i; ++j)
        {
            if (arr[j - 1] > arr[j])
            {
                temp = arr[j];
                arr[j] = arr[j - 1];
                arr[j - 1] = temp;
                flag = 1;
            }
        }
        if (flag == 0) return;
    }
}

int main(int argc, char const *argv[])
{
    int arr[7] = {2, 3, 4, 1, 7, 5, 6};
    bubleSort(arr, 7);

    for (int i = 0; i < 7; ++i)
    {
        printf("%d ", arr[i]);
    }
    getchar();
    return 0;
}
```





#### 快速排序




#### 选择排序

简单选择排序、树形选择排序和堆排序。













### 外部排序算法





















